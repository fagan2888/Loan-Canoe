{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the work\n",
    "\n",
    "\n",
    "*Purpose: This notebook breaks down step-by-step a simple wrangling approach to creating a training data of 50,000 records (data is already pre-recorded randomly in original raw csv) for your single year (i.e. 2013, 2015, and 2017)*.\n",
    "\n",
    "Documentation:  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html  \n",
    "https://stackoverflow.com/questions/23103962/how-to-write-dataframe-to-postgres-table                    \n",
    "https://github.com/metabase/metabase/issues/7214  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from pylab import*\n",
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new engine to specify the \"master\" permissions\n",
    "postgres_host = 'YOUR AWS DATA INSTANCE'  \n",
    "postgres_port = 'YOUR AWS PORT' \n",
    "postgres_username = 'YOUR AWS MASTER USERNAMME'\n",
    "postgres_password = 'YOUR AWS PWS'\n",
    "postgres_dbname = \"paddle_loan_canoe\"\n",
    "postgres_str = ('postgresql://{username}:{password}@{host}:{port}/{dbname}'\n",
    "                .format(username = postgres_username,\n",
    "                        password = postgres_password,\n",
    "                        host = postgres_host,\n",
    "                        port = postgres_port,\n",
    "                        dbname = postgres_dbname)\n",
    "               )\n",
    "\n",
    "\n",
    "# Creating the connection.\n",
    "cnx_m = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reading YOUR HMDA YEAR (i.e. 2013, 2015, 2017 -- a single year) dataset; join population and education datasets appropriately for YOUR YEAR \n",
    "#  for the first 50,000 rows -- as a dataframe using pandas: df.\n",
    "\n",
    "df = pd.read_sql_query ('''SELECT \n",
    "                              --> a. main: casting a few key MORTGAGE data fields:\n",
    "                                   CAST(us17.action_taken_name As varchar(56)) As outcome, us17.as_of_year As year,\n",
    "                                   CAST(denial_reason_name_1 As varchar(56)) dn_reason1 , CAST(us17.agency_name As varchar(56)) As agency,\n",
    "                                   CAST(us17.state_name As varchar(28)) As state,         CAST(us17.county_name As varchar(56)) As county,\n",
    "                                   CAST(us17.loan_type_name As varchar(56)) As ln_type,   CAST(us17.loan_purpose_name As varchar(56)) As ln_purp, \n",
    "                                   us17.loan_amount_000s As ln_amt_000s, us17.hud_median_family_income As hud_med_fm_inc, population as pop,\n",
    "\n",
    "                                       --two embedded fuctions and one CASE below: assigns hierarchy in CASE, and converts to num in two steps\n",
    "                                   CAST ( CAST ( CASE\n",
    "                                                     WHEN us17.rate_spread = '' Then '0'\n",
    "                                                     ELSE us17.rate_spread\n",
    "                                                 END As varchar(5)\n",
    "                                               ) As numeric\n",
    "                                        )\n",
    "                                   As rt_spread,\n",
    "                                       --categorize loan application outcome into two buckets: \"Approved\", \"Denied, Not Accepted, or Withdrawn\"\n",
    "                                   CASE\n",
    "                                       WHEN us17.action_taken_name In ('Loan originated', 'Loan purchased by the institution')\n",
    "                                           THEN 'Approved or Loan Purchased by the Institution'\n",
    "                                       ELSE 'Denied, Not Accepted, or Withdrawn'\n",
    "                                   END outcome_bucket,\n",
    "                              --*\n",
    "                              --> b. macro-econ: casting and joining a few key EDUCATION data fields:\n",
    "                                   CAST(educ17.\"Perc_adults w_less than a HS diploma_2013-17\" As int)  As prc_blw_HS__2013_17_5yrAvg,\n",
    "                                   CAST(educ17.\"Perc_adults w_ HS diploma only_2013-17\" As int)        As prc_HS__2013_17_5yrAvg,\n",
    "                                   CAST(educ17.\"Perc_adults w_BA deg or higher_2013-17\" As int)        As prc_BA_plus__2013_17_5yrAvg,\n",
    "                              --*\n",
    "                              --> c. macro-econ: casting and joining a few key POPULATION data fields:\n",
    "                                   CAST(pop17.r_birth_2017 AS INT)                                     As r_birth_2017,\n",
    "                                   CAST(pop17.r_international_mig_2017 AS INT)                         As r_intl_mig_2017,\n",
    "                                   CAST(pop17.r_natural_inc_2017 AS INT)                               As r_natural_inc_2017\n",
    "                              --*\n",
    "                           FROM YOUR SCHEMA.YOUR_YEAR us17 \n",
    "                           LEFT OUTER JOIN YOUR_SCHEMA.education__acs_1970_to_2017_5yravgs educ17 \n",
    "                                   ON us17.county_name = educ17.\"Area name\"\n",
    "                           LEFT OUTER JOIN YOUR_SCHEMA.populationestimates__usda_ers_2010_to_2018 pop17\n",
    "                                   ON us17.county_name = pop17.area_name\n",
    "                           LIMIT 50000''', cnx)\n",
    "\n",
    "# Using pandas to view the first 5 rows (NB: why does it start at 0?).\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PostgreSQL to count and group by the merged \"r_\" variables to see null values with \"\" appearing as INT\n",
    "df_test = pd.read_sql_query ('''WITH count_r_vars AS \n",
    "                                ( SELECT \n",
    "                              \n",
    "                                   CAST(us17.action_taken_name As varchar(56)) As outcome, us17.as_of_year As year,\n",
    "                                   CAST(denial_reason_name_1 As varchar(56)) dn_reason1 , CAST(us17.agency_name As varchar(56)) As agency,\n",
    "                                   CAST(us17.state_name As varchar(28)) As state,         CAST(us17.county_name As varchar(56)) As county,\n",
    "                                   CAST(educ17.\"Perc_adults w_less than a HS diploma_2013-17\" As int)  As prc_blw_HS__2013_17_5yrAvg,\n",
    "                                   CAST(educ17.\"Perc_adults w_ HS diploma only_2013-17\" As int)        As prc_HS__2013_17_5yrAvg,\n",
    "                                   CAST(educ17.\"Perc_adults w_BA deg or higher_2013-17\" As int)        As prc_BA_plus__2013_17_5yrAvg,\n",
    "                                   CAST(pop17.r_birth_2017 AS INT)                                     As r_birth_2017,\n",
    "                                   CAST(pop17.r_international_mig_2017 AS INT)                         As r_intl_mig_2017,\n",
    "                                   CAST(pop17.r_natural_inc_2017 AS INT)                               As r_natural_inc_2017\n",
    "\n",
    "\n",
    "                                   FROM YOUR_SCHEMAt.YOUR_YEAR7 us17 \n",
    "                                   LEFT OUTER JOIN YOUR_SCHEMA.YOUR_YEAR educ17 \n",
    "                                           ON us17.county_name = educ17.\"Area name\"\n",
    "                                   LEFT OUTER JOIN YOUR_SCHEMA.populationestimates__usda_ers_2010_to_2018 pop17\n",
    "                                           ON us17.county_name = pop17.area_name\n",
    "                                   LIMIT 50000\n",
    "                                ) \n",
    "                                SELECT 'r_birth_2017' As r_var__nm, COUNT(*) As null_counts FROM count_r_vars WHERE r_birth_2017 IS NULL\n",
    "                                    UNION ALL\n",
    "                                SELECT 'r_intl_mig_2017' As r_var__nm, COUNT(*) As null_counts  FROM count_r_vars WHERE r_birth_2017 IS NULL\n",
    "                                    UNION ALL\n",
    "                                SELECT 'r_nat_inc_2017' As r_var_nm, COUNT(*) As null_counts FROM count_r_vars WHERE r_natural_inc_2017 IS NULL\n",
    "                                '''           \n",
    "                             , cnx)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit your prelimary analysis to just loan applications for $700K or less\n",
    "\n",
    "df2 = df[df.ln_amt_000s < 700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note (For the years from 2013-2017): Since the ``` > $100K``` median household incomes appear to be outliers, we'll replace them with ```= $91K```, since it is the top of the upper wishker and therefore falls within the last quartile. Note, this is for preliminary modeling only and could not \"standardized\" so simply in our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna(subset=['r_natural_inc_2017', 'r_birth_2017', 'r_intl_mig_2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_dtype = {'outcome': sqlalchemy.types.VARCHAR(length=56),        'year':  sqlalchemy.types.INTEGER(),\n",
    "             'dn_reason1': sqlalchemy.types.VARCHAR(length=56),     'agency': sqlalchemy.types.VARCHAR(length=56), \n",
    "             'state': sqlalchemy.types.VARCHAR(length=28),          'county': sqlalchemy.types.VARCHAR(length=56), \n",
    "             'ln_type': sqlalchemy.types.VARCHAR(length=56),        'ln_purp': sqlalchemy.types.VARCHAR(length=56),\n",
    "             'ln_amt_000s': sqlalchemy.types.INTEGER(),             'hud_med_fm_inc': sqlalchemy.types.INTEGER(),\n",
    "             'pop': sqlalchemy.types.INTEGER(),                     'rt_spread': sqlalchemy.types.NUMERIC(),\n",
    "             'outcome_bucket': sqlalchemy.types.VARCHAR(length=56), 'prc_blw_HS__2013_17_5yrAvg': sqlalchemy.types.INTEGER(),\n",
    "             'prc_HS__2013_17_5yrAvg': sqlalchemy.types.INTEGER(),  'prc_BA_plus__2013_17_5yrAvg': sqlalchemy.types.INTEGER(),\n",
    "             'r_birth_2017': sqlalchemy.types.INTEGER(),            'r_intl_mig_2017': sqlalchemy.types.INTEGER(),\n",
    "             'r_natural_inc_2017': sqlalchemy.types.INTEGER()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas to write Dataframe to PostgreSQL and replacing table if it already exists\n",
    "df3.to_sql(name='loans_2017__training', schema='aa__testing', chunksize=250,\n",
    "           dtype= df3_dtype, method=None, con=cnx_m, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
