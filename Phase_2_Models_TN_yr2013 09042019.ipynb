{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import json \n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold #ensure allows for randomization\n",
    "from sklearn.model_selection import train_test_split as tts #drop this if using KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in data, create the two binaries that I have to create outside the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 24 columns):\n",
      "tract_to_msamd_income             48110 non-null float64\n",
      "population                        48115 non-null float64\n",
      "minority_population               48115 non-null float64\n",
      "number_of_owner_occupied_units    48104 non-null float64\n",
      "number_of_1_to_4_family_units     48107 non-null float64\n",
      "loan_amount_000s                  50000 non-null int64\n",
      "hud_median_family_income          48116 non-null float64\n",
      "applicant_income_000s             50000 non-null float64\n",
      "property_type_name                50000 non-null object\n",
      "owner_occupancy_name              50000 non-null object\n",
      "loan_type_name                    50000 non-null object\n",
      "loan_purpose_name                 50000 non-null object\n",
      "lien_status_name                  50000 non-null object\n",
      "hoepa_status_name                 50000 non-null object\n",
      "co_applicant_sex_name             50000 non-null object\n",
      "co_applicant_race_name_1          50000 non-null object\n",
      "co_applicant_ethnicity_name       50000 non-null object\n",
      "as_of_year                        50000 non-null int64\n",
      "applicant_sex_name                50000 non-null object\n",
      "applicant_race_name_1             50000 non-null object\n",
      "applicant_ethnicity_name          50000 non-null object\n",
      "agency_abbr                       50000 non-null object\n",
      "locality_type                     50000 non-null int64\n",
      "action_taken                      50000 non-null int64\n",
      "dtypes: float64(7), int64(4), object(13)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.abspath(os.path.join(\"/Users/tamananaheeme/Desktop/fixtures/hmda2013sample_balanced.csv\"))\n",
    "dataset = pd.read_csv(filepath, low_memory=False)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>property_type_name</th>\n",
       "      <th>owner_occupancy_name</th>\n",
       "      <th>...</th>\n",
       "      <th>co_applicant_sex_name</th>\n",
       "      <th>co_applicant_race_name_1</th>\n",
       "      <th>co_applicant_ethnicity_name</th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>applicant_sex_name</th>\n",
       "      <th>applicant_race_name_1</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>locality_type</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48110.000000</td>\n",
       "      <td>48115.000000</td>\n",
       "      <td>48115.000000</td>\n",
       "      <td>48104.000000</td>\n",
       "      <td>48107.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>48116.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-to-four family dwelling (other than manufa...</td>\n",
       "      <td>Owner-occupied as a principal dwelling</td>\n",
       "      <td>...</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>CFPB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48195</td>\n",
       "      <td>44339</td>\n",
       "      <td>...</td>\n",
       "      <td>25535</td>\n",
       "      <td>25535</td>\n",
       "      <td>25535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29882</td>\n",
       "      <td>34088</td>\n",
       "      <td>36558</td>\n",
       "      <td>24309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>115.300162</td>\n",
       "      <td>5354.659025</td>\n",
       "      <td>31.294497</td>\n",
       "      <td>1420.942915</td>\n",
       "      <td>1868.019394</td>\n",
       "      <td>203.121120</td>\n",
       "      <td>67477.148973</td>\n",
       "      <td>7425.796340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842020</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.033747</td>\n",
       "      <td>2637.838567</td>\n",
       "      <td>26.257307</td>\n",
       "      <td>724.386928</td>\n",
       "      <td>902.680785</td>\n",
       "      <td>554.861797</td>\n",
       "      <td>14495.695316</td>\n",
       "      <td>20606.344736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364726</td>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.350000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.422499</td>\n",
       "      <td>3723.000000</td>\n",
       "      <td>10.470000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>1297.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>58500.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.075001</td>\n",
       "      <td>4965.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>1328.000000</td>\n",
       "      <td>1742.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>65400.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134.617496</td>\n",
       "      <td>6395.000000</td>\n",
       "      <td>45.290001</td>\n",
       "      <td>1773.000000</td>\n",
       "      <td>2284.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>73400.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>486.940002</td>\n",
       "      <td>33201.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8526.000000</td>\n",
       "      <td>13227.000000</td>\n",
       "      <td>76985.000000</td>\n",
       "      <td>112200.000000</td>\n",
       "      <td>65400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tract_to_msamd_income    population  minority_population  \\\n",
       "count            48110.000000  48115.000000         48115.000000   \n",
       "unique                    NaN           NaN                  NaN   \n",
       "top                       NaN           NaN                  NaN   \n",
       "freq                      NaN           NaN                  NaN   \n",
       "mean               115.300162   5354.659025            31.294497   \n",
       "std                 42.033747   2637.838567            26.257307   \n",
       "min                  6.350000     33.000000             0.550000   \n",
       "25%                 88.422499   3723.000000            10.470000   \n",
       "50%                109.075001   4965.000000            22.500000   \n",
       "75%                134.617496   6395.000000            45.290001   \n",
       "max                486.940002  33201.000000           100.000000   \n",
       "\n",
       "        number_of_owner_occupied_units  number_of_1_to_4_family_units  \\\n",
       "count                     48104.000000                   48107.000000   \n",
       "unique                             NaN                            NaN   \n",
       "top                                NaN                            NaN   \n",
       "freq                               NaN                            NaN   \n",
       "mean                       1420.942915                    1868.019394   \n",
       "std                         724.386928                     902.680785   \n",
       "min                           7.000000                       6.000000   \n",
       "25%                         942.000000                    1297.000000   \n",
       "50%                        1328.000000                    1742.000000   \n",
       "75%                        1773.000000                    2284.000000   \n",
       "max                        8526.000000                   13227.000000   \n",
       "\n",
       "        loan_amount_000s  hud_median_family_income  applicant_income_000s  \\\n",
       "count       50000.000000              48116.000000           50000.000000   \n",
       "unique               NaN                       NaN                    NaN   \n",
       "top                  NaN                       NaN                    NaN   \n",
       "freq                 NaN                       NaN                    NaN   \n",
       "mean          203.121120              67477.148973            7425.796340   \n",
       "std           554.861797              14495.695316           20606.344736   \n",
       "min             1.000000              16400.000000               1.000000   \n",
       "25%            90.000000              58500.000000              48.000000   \n",
       "50%           150.000000              65400.000000              81.000000   \n",
       "75%           244.000000              73400.000000             149.000000   \n",
       "max         76985.000000             112200.000000           65400.000000   \n",
       "\n",
       "                                       property_type_name  \\\n",
       "count                                               50000   \n",
       "unique                                                  3   \n",
       "top     One-to-four family dwelling (other than manufa...   \n",
       "freq                                                48195   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                          owner_occupancy_name      ...       \\\n",
       "count                                    50000      ...        \n",
       "unique                                       3      ...        \n",
       "top     Owner-occupied as a principal dwelling      ...        \n",
       "freq                                     44339      ...        \n",
       "mean                                       NaN      ...        \n",
       "std                                        NaN      ...        \n",
       "min                                        NaN      ...        \n",
       "25%                                        NaN      ...        \n",
       "50%                                        NaN      ...        \n",
       "75%                                        NaN      ...        \n",
       "max                                        NaN      ...        \n",
       "\n",
       "       co_applicant_sex_name co_applicant_race_name_1  \\\n",
       "count                  50000                    50000   \n",
       "unique                     5                        8   \n",
       "top          No co-applicant          No co-applicant   \n",
       "freq                   25535                    25535   \n",
       "mean                     NaN                      NaN   \n",
       "std                      NaN                      NaN   \n",
       "min                      NaN                      NaN   \n",
       "25%                      NaN                      NaN   \n",
       "50%                      NaN                      NaN   \n",
       "75%                      NaN                      NaN   \n",
       "max                      NaN                      NaN   \n",
       "\n",
       "       co_applicant_ethnicity_name as_of_year applicant_sex_name  \\\n",
       "count                        50000    50000.0              50000   \n",
       "unique                           5        NaN                  4   \n",
       "top                No co-applicant        NaN               Male   \n",
       "freq                         25535        NaN              29882   \n",
       "mean                           NaN     2013.0                NaN   \n",
       "std                            NaN        0.0                NaN   \n",
       "min                            NaN     2013.0                NaN   \n",
       "25%                            NaN     2013.0                NaN   \n",
       "50%                            NaN     2013.0                NaN   \n",
       "75%                            NaN     2013.0                NaN   \n",
       "max                            NaN     2013.0                NaN   \n",
       "\n",
       "       applicant_race_name_1 applicant_ethnicity_name  agency_abbr  \\\n",
       "count                  50000                    50000        50000   \n",
       "unique                     7                        4            6   \n",
       "top                    White   Not Hispanic or Latino         CFPB   \n",
       "freq                   34088                    36558        24309   \n",
       "mean                     NaN                      NaN          NaN   \n",
       "std                      NaN                      NaN          NaN   \n",
       "min                      NaN                      NaN          NaN   \n",
       "25%                      NaN                      NaN          NaN   \n",
       "50%                      NaN                      NaN          NaN   \n",
       "75%                      NaN                      NaN          NaN   \n",
       "max                      NaN                      NaN          NaN   \n",
       "\n",
       "       locality_type  action_taken  \n",
       "count   50000.000000  50000.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean        0.842020      0.500000  \n",
       "std         0.364726      0.500005  \n",
       "min         0.000000      0.000000  \n",
       "25%         1.000000      0.000000  \n",
       "50%         1.000000      0.500000  \n",
       "75%         1.000000      1.000000  \n",
       "max         1.000000      1.000000  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "remove = ['purchaser_type_name',\n",
    "        'preapproval_name',\n",
    "        'rate_spread', \n",
    "        'sequence_number', \n",
    "        'respondent_id',\n",
    "        'state_name',\n",
    "        'state_abbr',\n",
    "        'county_name',\n",
    "        'edit_status_name', \n",
    "        'denial_reason_name_3', \n",
    "        'denial_reason_name_2', \n",
    "        'denial_reason_name_1', \n",
    "        'co_applicant_race_name_5', \n",
    "        'co_applicant_race_name_4', \n",
    "        'co_applicant_race_name_3', \n",
    "        'co_applicant_race_name_2',\n",
    "        'census_tract_number',\n",
    "        'application_date_indicator', \n",
    "        'applicant_race_name_5', \n",
    "        'applicant_race_name_4', \n",
    "        'applicant_race_name_3', \n",
    "        'applicant_race_name_2', \n",
    "        'agency_name',\n",
    "        'action_taken_name', \n",
    "        'msamd_nm']\n",
    "\n",
    "non_bool_numeric = ['tract_to_msamd_income', \n",
    "        'population', \n",
    "        'minority_population', \n",
    "        'number_of_owner_occupied_units', \n",
    "        'number_of_1_to_4_family_units', \n",
    "        'loan_amount_000s', \n",
    "        'hud_median_family_income', \n",
    "        'applicant_income_000s',\n",
    "        ]\n",
    "\n",
    "categorical = ['property_type_name', \n",
    "        'owner_occupancy_name', \n",
    "        'loan_type_name', \n",
    "        'loan_purpose_name',\n",
    "        'lien_status_name', \n",
    "        'hoepa_status_name', \n",
    "        'co_applicant_sex_name',\n",
    "        'co_applicant_race_name_1', \n",
    "        'co_applicant_ethnicity_name', \n",
    "        'as_of_year',\n",
    "        'applicant_sex_name', \n",
    "        'applicant_race_name_1',\n",
    "        'applicant_ethnicity_name', \n",
    "        'agency_abbr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(dataset.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[[col for col in dataset.columns if col != 'action_taken']]\n",
    "y = dataset['action_taken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24)\n",
      "(50000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>property_type_name</th>\n",
       "      <th>owner_occupancy_name</th>\n",
       "      <th>...</th>\n",
       "      <th>co_applicant_sex_name</th>\n",
       "      <th>co_applicant_race_name_1</th>\n",
       "      <th>co_applicant_ethnicity_name</th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>applicant_sex_name</th>\n",
       "      <th>applicant_race_name_1</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>locality_type</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-to-four family dwelling (other than manufa...</td>\n",
       "      <td>Owner-occupied as a principal dwelling</td>\n",
       "      <td>...</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>CFPB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48195</td>\n",
       "      <td>44339</td>\n",
       "      <td>...</td>\n",
       "      <td>25535</td>\n",
       "      <td>25535</td>\n",
       "      <td>25535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29882</td>\n",
       "      <td>34088</td>\n",
       "      <td>36558</td>\n",
       "      <td>24309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>115.300162</td>\n",
       "      <td>5354.659025</td>\n",
       "      <td>31.294497</td>\n",
       "      <td>1420.942915</td>\n",
       "      <td>1868.019394</td>\n",
       "      <td>203.121120</td>\n",
       "      <td>67477.148973</td>\n",
       "      <td>7425.796340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842020</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.231640</td>\n",
       "      <td>2587.636607</td>\n",
       "      <td>25.757592</td>\n",
       "      <td>710.519541</td>\n",
       "      <td>885.427817</td>\n",
       "      <td>554.861797</td>\n",
       "      <td>14219.968617</td>\n",
       "      <td>20606.344736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364726</td>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.350000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>89.410004</td>\n",
       "      <td>3775.000000</td>\n",
       "      <td>10.880000</td>\n",
       "      <td>957.000000</td>\n",
       "      <td>1315.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>58600.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.699997</td>\n",
       "      <td>5064.000000</td>\n",
       "      <td>23.865001</td>\n",
       "      <td>1358.000000</td>\n",
       "      <td>1779.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>66000.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>133.399994</td>\n",
       "      <td>6328.000000</td>\n",
       "      <td>44.020000</td>\n",
       "      <td>1751.000000</td>\n",
       "      <td>2258.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>73300.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>486.940002</td>\n",
       "      <td>33201.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8526.000000</td>\n",
       "      <td>13227.000000</td>\n",
       "      <td>76985.000000</td>\n",
       "      <td>112200.000000</td>\n",
       "      <td>65400.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tract_to_msamd_income    population  minority_population  \\\n",
       "count            50000.000000  50000.000000         50000.000000   \n",
       "unique                    NaN           NaN                  NaN   \n",
       "top                       NaN           NaN                  NaN   \n",
       "freq                      NaN           NaN                  NaN   \n",
       "mean               115.300162   5354.659025            31.294497   \n",
       "std                 41.231640   2587.636607            25.757592   \n",
       "min                  6.350000     33.000000             0.550000   \n",
       "25%                 89.410004   3775.000000            10.880000   \n",
       "50%                110.699997   5064.000000            23.865001   \n",
       "75%                133.399994   6328.000000            44.020000   \n",
       "max                486.940002  33201.000000           100.000000   \n",
       "\n",
       "        number_of_owner_occupied_units  number_of_1_to_4_family_units  \\\n",
       "count                     50000.000000                   50000.000000   \n",
       "unique                             NaN                            NaN   \n",
       "top                                NaN                            NaN   \n",
       "freq                               NaN                            NaN   \n",
       "mean                       1420.942915                    1868.019394   \n",
       "std                         710.519541                     885.427817   \n",
       "min                           7.000000                       6.000000   \n",
       "25%                         957.000000                    1315.000000   \n",
       "50%                        1358.000000                    1779.000000   \n",
       "75%                        1751.000000                    2258.000000   \n",
       "max                        8526.000000                   13227.000000   \n",
       "\n",
       "        loan_amount_000s  hud_median_family_income  applicant_income_000s  \\\n",
       "count       50000.000000              50000.000000           50000.000000   \n",
       "unique               NaN                       NaN                    NaN   \n",
       "top                  NaN                       NaN                    NaN   \n",
       "freq                 NaN                       NaN                    NaN   \n",
       "mean          203.121120              67477.148973            7425.796340   \n",
       "std           554.861797              14219.968617           20606.344736   \n",
       "min             1.000000              16400.000000               1.000000   \n",
       "25%            90.000000              58600.000000              48.000000   \n",
       "50%           150.000000              66000.000000              81.000000   \n",
       "75%           244.000000              73300.000000             149.000000   \n",
       "max         76985.000000             112200.000000           65400.000000   \n",
       "\n",
       "                                       property_type_name  \\\n",
       "count                                               50000   \n",
       "unique                                                  3   \n",
       "top     One-to-four family dwelling (other than manufa...   \n",
       "freq                                                48195   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                          owner_occupancy_name      ...       \\\n",
       "count                                    50000      ...        \n",
       "unique                                       3      ...        \n",
       "top     Owner-occupied as a principal dwelling      ...        \n",
       "freq                                     44339      ...        \n",
       "mean                                       NaN      ...        \n",
       "std                                        NaN      ...        \n",
       "min                                        NaN      ...        \n",
       "25%                                        NaN      ...        \n",
       "50%                                        NaN      ...        \n",
       "75%                                        NaN      ...        \n",
       "max                                        NaN      ...        \n",
       "\n",
       "       co_applicant_sex_name co_applicant_race_name_1  \\\n",
       "count                  50000                    50000   \n",
       "unique                     5                        8   \n",
       "top          No co-applicant          No co-applicant   \n",
       "freq                   25535                    25535   \n",
       "mean                     NaN                      NaN   \n",
       "std                      NaN                      NaN   \n",
       "min                      NaN                      NaN   \n",
       "25%                      NaN                      NaN   \n",
       "50%                      NaN                      NaN   \n",
       "75%                      NaN                      NaN   \n",
       "max                      NaN                      NaN   \n",
       "\n",
       "       co_applicant_ethnicity_name as_of_year applicant_sex_name  \\\n",
       "count                        50000    50000.0              50000   \n",
       "unique                           5        NaN                  4   \n",
       "top                No co-applicant        NaN               Male   \n",
       "freq                         25535        NaN              29882   \n",
       "mean                           NaN     2013.0                NaN   \n",
       "std                            NaN        0.0                NaN   \n",
       "min                            NaN     2013.0                NaN   \n",
       "25%                            NaN     2013.0                NaN   \n",
       "50%                            NaN     2013.0                NaN   \n",
       "75%                            NaN     2013.0                NaN   \n",
       "max                            NaN     2013.0                NaN   \n",
       "\n",
       "       applicant_race_name_1 applicant_ethnicity_name  agency_abbr  \\\n",
       "count                  50000                    50000        50000   \n",
       "unique                     7                        4            6   \n",
       "top                    White   Not Hispanic or Latino         CFPB   \n",
       "freq                   34088                    36558        24309   \n",
       "mean                     NaN                      NaN          NaN   \n",
       "std                      NaN                      NaN          NaN   \n",
       "min                      NaN                      NaN          NaN   \n",
       "25%                      NaN                      NaN          NaN   \n",
       "50%                      NaN                      NaN          NaN   \n",
       "75%                      NaN                      NaN          NaN   \n",
       "max                      NaN                      NaN          NaN   \n",
       "\n",
       "       locality_type  action_taken  \n",
       "count   50000.000000  50000.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean        0.842020      0.500000  \n",
       "std         0.364726      0.500005  \n",
       "min         0.000000      0.000000  \n",
       "25%         1.000000      0.000000  \n",
       "50%         1.000000      0.500000  \n",
       "75%         1.000000      1.000000  \n",
       "max         1.000000      1.000000  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(X.shape)\n",
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Dr. Bengfort's Census Notebook:\n",
    "\n",
    "This code creates a `meta.json` file by inspecting the data frame that we have constructued. The `target_names` column, is just the two unique values in the `data.income` series; by using the `pd.Series.unique` method - we're guarenteed to spot data errors if there are more or less than two values. The `feature_names` is simply the names of all the columns. \n",
    "\n",
    "Now that we have everything we need stored on disk, we can create a `load_data` function, which will allow us to load the training and test datasets appropriately from disk and store them in a `Bunch`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"/Users/tamananaheeme/Desktop/fixtures/hmda2013sample_balanced_formatted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    'target_names': [str(yi) for yi in y.unique()],\n",
    "    'feature_names': list(X.columns),\n",
    "    'categorical_features': {\n",
    "        column: list(X[column].unique())\n",
    "        for column in X.columns\n",
    "        if X[column].dtype == 'object'\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('data/meta.json', 'w') as f:\n",
    "     json.dump(meta, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 23)\n"
     ]
    }
   ],
   "source": [
    "def load_data(root=os.getcwd()):\n",
    "    # Construct the `Bunch` for the HMDA dataset\n",
    "    filenames     = {\n",
    "        'meta': os.path.join(root, 'data','meta.json'),\n",
    "        'rdme': os.path.join(root, 'data', 'readme.md'),\n",
    "        'data': os.path.abspath(os.path.join(\"/Users/tamananaheeme/Desktop/fixtures/hmda2013sample_balanced_formatted.csv\")),\n",
    "    }\n",
    "\n",
    "    # Load the meta data from the meta json\n",
    "    with open(filenames['meta'], 'r') as f:\n",
    "        meta = json.load(f)\n",
    "        target_names  = meta['target_names']\n",
    "        feature_names = meta['feature_names']\n",
    "\n",
    "    # Load the description from the README. \n",
    "    with open(filenames['rdme'], 'r') as f:\n",
    "        DESCR = f.read()\n",
    "\n",
    "    # Load the dataset from the text file.\n",
    "    dataset = pd.read_csv(filenames['data'], low_memory=False)\n",
    "\n",
    "    # Extract the target from the data\n",
    "    data = dataset[[col for col in dataset.columns if col != 'action_taken']]\n",
    "    target = dataset['action_taken']\n",
    "\n",
    "    # Create the bunch object\n",
    "    return Bunch(\n",
    "        data=data,\n",
    "        target=target,\n",
    "        filenames=filenames,\n",
    "        target_names=target_names,\n",
    "        feature_names=feature_names,\n",
    "        categorical_features = meta['categorical_features'], \n",
    "        DESCR=DESCR\n",
    "    )\n",
    "\n",
    "# Save the dataset as a variable we can use.\n",
    "dataset = load_data()\n",
    "\n",
    "print(dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Dr. Bengfort's Census Notebook:\n",
    "\n",
    "Now that we've finally acheived our feature extraction, we can continue on to the model build phase. To create our classifier, we're going to create a [`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that uses our feature transformers and ends in an estimator that can do classification. We can then write the entire pipeline object to disk with the `pickle`, allowing us to load it up and use it to make predictions in the future. \n",
    "\n",
    "A pipeline is a step-by-step set of transformers that takes input data and transforms it, until finally passing it to an estimator at the end. Pipelines can be constructed using a named declarative syntax so that they're easy to modify and develop. Our pipeline is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, non_bool_numeric),\n",
    "        ('cat', categorical_transformer, categorical)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 67)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(dataset.data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 67)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Source: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "categorical_indexes = [\n",
    "    list(dataset.data.columns).index(key) for key in dataset.categorical_features.keys()\n",
    "]\n",
    "\n",
    "tn_chart_preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categorical)])\n",
    "\n",
    "tn_chart_pipeline = Pipeline(steps=[('preprocessor', clone(preprocessor))])\n",
    "        \n",
    "chart_enc = tn_chart_pipeline\n",
    "\n",
    "X_CHARTS = chart_enc.fit_transform(dataset.data)\n",
    "X_CHARTS.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(X, y, model, label, **kwargs):\n",
    "\n",
    "    start  = time.time() # Start the clock! \n",
    "    #scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "\n",
    "    scores = {'precision':[], 'precision_1':[], 'precision_0':[], 'recall':[], 'recall_1':[], 'recall_0':[], 'accuracy':[], 'f1':[],  'f1_1':[],  'f1_0':[]}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 12, shuffle=True, random_state=1)\n",
    "    \n",
    "    for train, test in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        \n",
    "        estimator = Pipeline(steps=[('preprocessor', clone(preprocessor)),\n",
    "                      ('model', model(**kwargs))])\n",
    "        \n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        expected  = y_test\n",
    "        predicted = estimator.predict(X_test)\n",
    "        cr = classification_report(y_test, predicted, output_dict=True)\n",
    "        \n",
    "        # Append our scores to the tracker\n",
    "        scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['precision_1'].append(cr['1']['precision'])\n",
    "        scores['precision_0'].append(cr['0']['precision'])\n",
    "        scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['recall_1'].append(cr['1']['recall'])\n",
    "        scores['recall_0'].append(cr['0']['recall'])\n",
    "        scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "        scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['f1_1'].append(cr['1']['f1-score'])\n",
    "        scores['f1_0'].append(cr['0']['f1-score'])\n",
    "        \n",
    "    # Report\n",
    "    print(\"Build and Validation of {} took {:0.3f} seconds\".format(label, time.time()-start))\n",
    "    print(\"Validation scores are as follows:\\n\")\n",
    "    print(pd.DataFrame(scores).mean())\n",
    "    \n",
    "    # Write official estimator to disk\n",
    "    estimator = Pipeline(steps=[('preprocessor', clone(preprocessor)),\n",
    "                      ('model', model(**kwargs))])\n",
    "    estimator.fit(X, y)\n",
    "    \n",
    "    outpath = label.lower().replace(\" \", \"-\") + \".pickle\"\n",
    "    with open(outpath, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "\n",
    "    print(\"\\nFitted model written to:\\n{}\".format(os.path.abspath(outpath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA Logistic Regression took 11.379 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.671752\n",
      "precision_1    0.707092\n",
      "precision_0    0.636412\n",
      "recall         0.664460\n",
      "recall_1       0.561600\n",
      "recall_0       0.767320\n",
      "accuracy       0.664460\n",
      "f1             0.660861\n",
      "f1_1           0.625974\n",
      "f1_0           0.695747\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-logistic-regression.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, LogisticRegression, \"HMDA Logistic Regression\", max_iter=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA Random Forest Classifier took 95.716 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.685883\n",
      "precision_1    0.709009\n",
      "precision_0    0.662757\n",
      "recall         0.682959\n",
      "recall_1       0.620599\n",
      "recall_0       0.745320\n",
      "accuracy       0.682959\n",
      "f1             0.681698\n",
      "f1_1           0.661812\n",
      "f1_0           0.701584\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-random-forest-classifier.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, RandomForestClassifier, \"HMDA Random Forest Classifier\", n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA Linear Discriminant Analysis took 7.777 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.672809\n",
      "precision_1    0.712099\n",
      "precision_0    0.633518\n",
      "recall         0.663860\n",
      "recall_1       0.550160\n",
      "recall_0       0.777559\n",
      "accuracy       0.663860\n",
      "f1             0.659447\n",
      "f1_1           0.620718\n",
      "f1_0           0.698177\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-linear-discriminant-analysis.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, LinearDiscriminantAnalysis, \"HMDA Linear Discriminant Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA LinearSVC took 91.909 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.672186\n",
      "precision_1    0.709082\n",
      "precision_0    0.635289\n",
      "recall         0.664260\n",
      "recall_1       0.557120\n",
      "recall_0       0.771400\n",
      "accuracy       0.664260\n",
      "f1             0.660350\n",
      "f1_1           0.623953\n",
      "f1_0           0.696746\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-linearsvc.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, LinearSVC, \"HMDA LinearSVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA BernoulliNB took 3.788 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.655840\n",
      "precision_1    0.697257\n",
      "precision_0    0.614423\n",
      "recall         0.644800\n",
      "recall_1       0.512001\n",
      "recall_0       0.777600\n",
      "accuracy       0.644800\n",
      "f1             0.638404\n",
      "f1_1           0.590382\n",
      "f1_0           0.686425\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-bernoullinb.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, BernoulliNB, \"HMDA BernoulliNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA GaussianNB took 3.953 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.769772\n",
      "precision_1    0.969578\n",
      "precision_0    0.569967\n",
      "recall         0.621760\n",
      "recall_1       0.251440\n",
      "recall_0       0.992080\n",
      "accuracy       0.621760\n",
      "f1             0.561604\n",
      "f1_1           0.399224\n",
      "f1_0           0.723984\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-gaussiannb.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, GaussianNB, \"HMDA GaussianNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA DecisionTreeClassifier took 11.764 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.624199\n",
      "precision_1    0.623032\n",
      "precision_0    0.625367\n",
      "recall         0.624159\n",
      "recall_1       0.628999\n",
      "recall_0       0.619319\n",
      "accuracy       0.624159\n",
      "f1             0.624126\n",
      "f1_1           0.625964\n",
      "f1_0           0.622289\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-decisiontreeclassifier.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, tree.DecisionTreeClassifier, \"HMDA DecisionTreeClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA BaggingClassifier took 56.323 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.667550\n",
      "precision_1    0.697444\n",
      "precision_0    0.637657\n",
      "recall         0.662180\n",
      "recall_1       0.572719\n",
      "recall_0       0.751640\n",
      "accuracy       0.662180\n",
      "f1             0.659426\n",
      "f1_1           0.628906\n",
      "f1_0           0.689945\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-baggingclassifier.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, BaggingClassifier, \"HMDA BaggingClassifier\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA ExtraTreesClassifier took 78.540 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.666152\n",
      "precision_1    0.680513\n",
      "precision_0    0.651791\n",
      "recall         0.664879\n",
      "recall_1       0.621479\n",
      "recall_0       0.708280\n",
      "accuracy       0.664879\n",
      "f1             0.664228\n",
      "f1_1           0.649620\n",
      "f1_0           0.678835\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-extratreesclassifier.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, ExtraTreesClassifier, \"HMDA ExtraTreesClassifier\", n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA SGDClassifier took 3.768 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision      0.653693\n",
      "precision_1    0.679850\n",
      "precision_0    0.627535\n",
      "recall         0.632101\n",
      "recall_1       0.576354\n",
      "recall_0       0.687849\n",
      "accuracy       0.632101\n",
      "f1             0.618256\n",
      "f1_1           0.601452\n",
      "f1_0           0.635060\n",
      "dtype: float64\n",
      "\n",
      "Fitted model written to:\n",
      "/Users/tamananaheeme/Desktop/GU_DS/Loan-Canoe/foo/hmda-sgdclassifier.pickle\n"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, SGDClassifier, \"HMDA SGDClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to save our model to disk for reuse later, with the `pickle` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle \n",
    "\n",
    "def dump_model(model, path='data', name='classifier.pickle'):\n",
    "    with open(os.path.join(path, name), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "dump_model(census)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
