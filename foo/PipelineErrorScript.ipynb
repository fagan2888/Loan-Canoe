{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import json \n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import KFold #ensure allows for randomization\n",
    "from sklearn.model_selection import train_test_split as tts #drop this if using KFold\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.abspath(os.path.join( \"..\", \"fixtures\", \"hmda2017sample_balanced.csv\"))\n",
    "DATA = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "DATA['locality_type'] = None\n",
    "cloc = DATA.columns.get_loc('locality_type')\n",
    "i = 0\n",
    "for x in DATA['msamd_name'].isna():\n",
    "    if x == True:\n",
    "        DATA.iat[i, cloc]= 0\n",
    "        \n",
    "    else: \n",
    "        DATA.iat[i, cloc]= 1\n",
    "        \n",
    "    i+=1\n",
    "        \n",
    "DATA['locality_type'] = DATA['locality_type'].astype('int64')\n",
    "\n",
    "DATA['action_taken'] = DATA.action_taken_name.apply(lambda x: 1 if x in ['Loan purchased by the institution', 'Loan originated'] else 0)\n",
    "\n",
    "DATA['applicant_income_000s'].fillna(DATA.hud_median_family_income.median(), inplace=True)\n",
    "\n",
    "remove = ['purchaser_type_name',\n",
    "        'preapproval_name',\n",
    "        'rate_spread', \n",
    "        'sequence_number', \n",
    "        'respondent_id',\n",
    "        'state_name',\n",
    "        'state_abbr',\n",
    "        'county_name',\n",
    "        'edit_status_name', \n",
    "        'denial_reason_name_3', \n",
    "        'denial_reason_name_2', \n",
    "        'denial_reason_name_1', \n",
    "        'co_applicant_race_name_5', \n",
    "        'co_applicant_race_name_4', \n",
    "        'co_applicant_race_name_3', \n",
    "        'co_applicant_race_name_2',\n",
    "        'census_tract_number',\n",
    "        'application_date_indicator', \n",
    "        'applicant_race_name_5', \n",
    "        'applicant_race_name_4', \n",
    "        'applicant_race_name_3', \n",
    "        'applicant_race_name_2', \n",
    "        'agency_name',\n",
    "        'action_taken_name', \n",
    "        'msamd_name']\n",
    "\n",
    "int_float = ['tract_to_msamd_income', \n",
    "        'population', \n",
    "        'minority_population', \n",
    "        'number_of_owner_occupied_units', \n",
    "        'number_of_1_to_4_family_units', \n",
    "        'loan_amount_000s', \n",
    "        'hud_median_family_income', \n",
    "        'applicant_income_000s',\n",
    "        'locality_type']\n",
    "\n",
    "categorical = ['property_type_name', \n",
    "        'owner_occupancy_name', \n",
    "        'loan_type_name', \n",
    "        'loan_purpose_name',\n",
    "        'lien_status_name', \n",
    "        'hoepa_status_name', \n",
    "        'co_applicant_sex_name',\n",
    "        'co_applicant_race_name_1', \n",
    "        'co_applicant_ethnicity_name', \n",
    "        'as_of_year',\n",
    "        'applicant_sex_name', \n",
    "        'applicant_race_name_1',\n",
    "        'applicant_ethnicity_name', \n",
    "        'agency_abbr']\n",
    "\n",
    "DATA = DATA.drop(DATA.columns[0], axis=1)\n",
    "DATA = DATA.drop(remove, axis=1)\n",
    "X = DATA[[col for col in DATA.columns if col != 'action_taken']]\n",
    "y = DATA['action_taken']\n",
    "\n",
    "filepath = os.path.abspath(os.path.join( \"..\", \"fixtures\", \"hmda2017sample_balanced_formatted.csv\"))\n",
    "DATA.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24)\n",
      "(50000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>property_type_name</th>\n",
       "      <th>owner_occupancy_name</th>\n",
       "      <th>...</th>\n",
       "      <th>co_applicant_sex_name</th>\n",
       "      <th>co_applicant_race_name_1</th>\n",
       "      <th>co_applicant_ethnicity_name</th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>applicant_sex_name</th>\n",
       "      <th>applicant_race_name_1</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>locality_type</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One-to-four family dwelling (other than manufa...</td>\n",
       "      <td>Owner-occupied as a principal dwelling</td>\n",
       "      <td>...</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>No co-applicant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>HUD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47112</td>\n",
       "      <td>45053</td>\n",
       "      <td>...</td>\n",
       "      <td>27495</td>\n",
       "      <td>27495</td>\n",
       "      <td>27495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28255</td>\n",
       "      <td>32128</td>\n",
       "      <td>34673</td>\n",
       "      <td>24817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.760058</td>\n",
       "      <td>5633.718300</td>\n",
       "      <td>33.533193</td>\n",
       "      <td>1434.35328</td>\n",
       "      <td>1977.296320</td>\n",
       "      <td>228.458040</td>\n",
       "      <td>70502.446000</td>\n",
       "      <td>7906.332320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883040</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.470068</td>\n",
       "      <td>3012.190961</td>\n",
       "      <td>27.023663</td>\n",
       "      <td>833.92800</td>\n",
       "      <td>1033.910772</td>\n",
       "      <td>591.345455</td>\n",
       "      <td>15045.781898</td>\n",
       "      <td>21643.441935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321376</td>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15800.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>84.839996</td>\n",
       "      <td>3826.000000</td>\n",
       "      <td>11.530000</td>\n",
       "      <td>909.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>61100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>105.470001</td>\n",
       "      <td>5120.000000</td>\n",
       "      <td>25.160000</td>\n",
       "      <td>1301.00000</td>\n",
       "      <td>1808.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>67900.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>130.552502</td>\n",
       "      <td>6726.000000</td>\n",
       "      <td>50.049999</td>\n",
       "      <td>1782.00000</td>\n",
       "      <td>2397.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>76300.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>468.000000</td>\n",
       "      <td>53812.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19529.00000</td>\n",
       "      <td>25391.000000</td>\n",
       "      <td>68000.000000</td>\n",
       "      <td>131500.000000</td>\n",
       "      <td>132000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tract_to_msamd_income    population  minority_population  \\\n",
       "count            50000.000000  50000.000000         50000.000000   \n",
       "unique                    NaN           NaN                  NaN   \n",
       "top                       NaN           NaN                  NaN   \n",
       "freq                      NaN           NaN                  NaN   \n",
       "mean               110.760058   5633.718300            33.533193   \n",
       "std                 40.470068   3012.190961            27.023663   \n",
       "min                  0.000000     87.000000             0.000000   \n",
       "25%                 84.839996   3826.000000            11.530000   \n",
       "50%                105.470001   5120.000000            25.160000   \n",
       "75%                130.552502   6726.000000            50.049999   \n",
       "max                468.000000  53812.000000           100.000000   \n",
       "\n",
       "        number_of_owner_occupied_units  number_of_1_to_4_family_units  \\\n",
       "count                      50000.00000                   50000.000000   \n",
       "unique                             NaN                            NaN   \n",
       "top                                NaN                            NaN   \n",
       "freq                               NaN                            NaN   \n",
       "mean                        1434.35328                    1977.296320   \n",
       "std                          833.92800                    1033.910772   \n",
       "min                            0.00000                       0.000000   \n",
       "25%                          909.00000                    1332.000000   \n",
       "50%                         1301.00000                    1808.000000   \n",
       "75%                         1782.00000                    2397.000000   \n",
       "max                        19529.00000                   25391.000000   \n",
       "\n",
       "        loan_amount_000s  hud_median_family_income  applicant_income_000s  \\\n",
       "count       50000.000000              50000.000000           50000.000000   \n",
       "unique               NaN                       NaN                    NaN   \n",
       "top                  NaN                       NaN                    NaN   \n",
       "freq                 NaN                       NaN                    NaN   \n",
       "mean          228.458040              70502.446000            7906.332320   \n",
       "std           591.345455              15045.781898           21643.441935   \n",
       "min             1.000000              15800.000000               1.000000   \n",
       "25%            97.000000              61100.000000              50.000000   \n",
       "50%           172.000000              67900.000000              82.000000   \n",
       "75%           279.000000              76300.000000             150.000000   \n",
       "max         68000.000000             131500.000000          132000.000000   \n",
       "\n",
       "                                       property_type_name  \\\n",
       "count                                               50000   \n",
       "unique                                                  3   \n",
       "top     One-to-four family dwelling (other than manufa...   \n",
       "freq                                                47112   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                          owner_occupancy_name  ... co_applicant_sex_name  \\\n",
       "count                                    50000  ...                 50000   \n",
       "unique                                       3  ...                     5   \n",
       "top     Owner-occupied as a principal dwelling  ...       No co-applicant   \n",
       "freq                                     45053  ...                 27495   \n",
       "mean                                       NaN  ...                   NaN   \n",
       "std                                        NaN  ...                   NaN   \n",
       "min                                        NaN  ...                   NaN   \n",
       "25%                                        NaN  ...                   NaN   \n",
       "50%                                        NaN  ...                   NaN   \n",
       "75%                                        NaN  ...                   NaN   \n",
       "max                                        NaN  ...                   NaN   \n",
       "\n",
       "       co_applicant_race_name_1 co_applicant_ethnicity_name as_of_year  \\\n",
       "count                     50000                       50000    50000.0   \n",
       "unique                        8                           5        NaN   \n",
       "top             No co-applicant             No co-applicant        NaN   \n",
       "freq                      27495                       27495        NaN   \n",
       "mean                        NaN                         NaN     2017.0   \n",
       "std                         NaN                         NaN        0.0   \n",
       "min                         NaN                         NaN     2017.0   \n",
       "25%                         NaN                         NaN     2017.0   \n",
       "50%                         NaN                         NaN     2017.0   \n",
       "75%                         NaN                         NaN     2017.0   \n",
       "max                         NaN                         NaN     2017.0   \n",
       "\n",
       "       applicant_sex_name applicant_race_name_1 applicant_ethnicity_name  \\\n",
       "count               50000                 50000                    50000   \n",
       "unique                  4                     7                        4   \n",
       "top                  Male                 White   Not Hispanic or Latino   \n",
       "freq                28255                 32128                    34673   \n",
       "mean                  NaN                   NaN                      NaN   \n",
       "std                   NaN                   NaN                      NaN   \n",
       "min                   NaN                   NaN                      NaN   \n",
       "25%                   NaN                   NaN                      NaN   \n",
       "50%                   NaN                   NaN                      NaN   \n",
       "75%                   NaN                   NaN                      NaN   \n",
       "max                   NaN                   NaN                      NaN   \n",
       "\n",
       "        agency_abbr locality_type  action_taken  \n",
       "count         50000  50000.000000  50000.000000  \n",
       "unique            6           NaN           NaN  \n",
       "top             HUD           NaN           NaN  \n",
       "freq          24817           NaN           NaN  \n",
       "mean            NaN      0.883040      0.500000  \n",
       "std             NaN      0.321376      0.500005  \n",
       "min             NaN      0.000000      0.000000  \n",
       "25%             NaN      1.000000      0.000000  \n",
       "50%             NaN      1.000000      0.500000  \n",
       "75%             NaN      1.000000      1.000000  \n",
       "max             NaN      1.000000      1.000000  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(DATA.shape)\n",
    "print(X.shape)\n",
    "DATA.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the CSV data doesn't have a header row, I had to supply the names directly to the `pd.read_csv` function. To get these names, I manually constructed the list by reading the `adult.names` file. In the future, we'll store these names as a machine readable JSON file so that we don't have to manuually construct it. \n",
    "\n",
    "By glancing at the first 5 rows of the data, we can see that we have primarily categorical data. Our target, `data.income` is also currently constructed as a categorical field. Unfortunately, with categorical fields, we don't have a lot of visualization options (quite yet). However, it would be interesting to see the frequencies of each class, relative to the target of our classifier. To do this, we can use Seaborn's `countplot` function to count the occurrences of each data point. Let's take a look at the counts of `data.occupation` and `data.education` &mdash; two likely predictors of income in the census data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23434e649e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='action_taken', hue='property_type_name', data=DATA,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23435053eb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='action_taken', hue='owner_occupancy_name', data=DATA,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    'target_names': [str(yi) for yi in y.unique()],\n",
    "    'feature_names': list(X.columns),\n",
    "    'categorical_features': {\n",
    "        column: list(X[column].unique())\n",
    "        for column in X.columns\n",
    "        if X[column].dtype == 'object'\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('data/meta.json', 'w') as f:\n",
    "     json.dump(meta, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a `meta.json` file by inspecting the data frame that we have constructued. The `target_names` column, is just the two unique values in the `data.income` series; by using the `pd.Series.unique` method - we're guarenteed to spot data errors if there are more or less than two values. The `feature_names` is simply the names of all the columns. \n",
    "\n",
    "Then we get tricky &mdash; we want to store the possible values of each categorical field for lookup later, but how do we know which columns are categorical and which are not? Luckily, Pandas has already done an analysis for us, and has stored the column data type, `data[column].dtype`, as either `int64` or `object`. Here I am using a dictionary comprehension to create a dictionary whose keys are the categorical columns, determined by checking the object type and comparing with `object`, and whose values are a list of unique values for that field. \n",
    "\n",
    "Now that we have everything we need stored on disk, we can create a `load_data` function, which will allow us to load the training and test datasets appropriately from disk and store them in a `Bunch`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 23)\n"
     ]
    }
   ],
   "source": [
    "def load_data(root=os.getcwd()):\n",
    "    # Construct the `Bunch` for the HMDA dataset\n",
    "    filenames     = {\n",
    "        'meta': os.path.join(root, 'data','meta.json'),\n",
    "        'rdme': os.path.join(\"..\",'readme.md'),\n",
    "        'data': os.path.abspath(os.path.join( \"..\", \"fixtures\", \"hmda2017sample_balanced_formatted.csv\")),\n",
    "    }\n",
    "\n",
    "    # Load the meta data from the meta json\n",
    "    with open(filenames['meta'], 'r') as f:\n",
    "        meta = json.load(f)\n",
    "        target_names  = meta['target_names']\n",
    "        feature_names = meta['feature_names']\n",
    "\n",
    "    # Load the description from the README. \n",
    "    with open(filenames['rdme'], 'r') as f:\n",
    "        DESCR = f.read()\n",
    "\n",
    "    # Load the dataset from the text file.\n",
    "    dataset = pd.read_csv(filenames['data'], low_memory=False)\n",
    "\n",
    "    # Extract the target from the data\n",
    "    data = dataset[[col for col in DATA.columns if col != 'action_taken']]\n",
    "    target = dataset['action_taken']\n",
    "\n",
    "    # Create the bunch object\n",
    "    return Bunch(\n",
    "        data=data,\n",
    "        target=target,\n",
    "        filenames=filenames,\n",
    "        target_names=target_names,\n",
    "        feature_names=feature_names,\n",
    "        categorical_features = meta['categorical_features'], \n",
    "        DESCR=DESCR\n",
    "    )\n",
    "\n",
    "# Save the dataset as a variable we can use.\n",
    "dataset = load_data()\n",
    "\n",
    "print(dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary work of the `load_data` function is to locate the appropriate files on disk, given a root directory that's passed in as an argument (if you saved your data in a different directory, you can modify the root to have it look in the right place). The meta data is included with the bunch, and is also used split the train and test datasets into `data` and `target` variables appropriately, such that we can pass them correctly to the Scikit-Learn `fit` and `predict` estimator methods. \n",
    "\n",
    "## Feature Extraction \n",
    "\n",
    "Now that our data management workflow is structured a bit more like Scikit-Learn, we can start to use our data to fit models. Unfortunately, the categorical values themselves are not useful for machine learning; we need a single instance table that contains _numeric values_. In order to extract this from the dataset, we'll have to use Scikit-Learn transformers to transform our input dataset into something that can be fit to a model. In particular, we'll have to do the following:\n",
    "\n",
    "- encode the categorical labels as numeric data \n",
    "- impute missing values with data (or remove)\n",
    "\n",
    "We will explore how to apply these transformations to our dataset, then we will create a feature extraction pipeline that we can use to build a model from the raw input data. This pipeline will apply both the imputer and the label encoders directly in front of our classifier, so that we can ensure that features are extracted appropriately in both the training and test datasets.  \n",
    "\n",
    "### Label Encoding \n",
    "\n",
    "Our first step is to get our data out of the object data type land and into a numeric type, since nearly all operations we'd like to apply to our data are going to rely on numeric types. Luckily, Sckit-Learn does provide a transformer for converting categorical labels into numeric integers: [`sklearn.preprocessing.LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Unfortunately it can only transform a single vector at a time, so we'll have to adapt it in order to apply it to multiple columns. \n",
    "\n",
    "Like all Scikit-Learn transformers, the `LabelEncoder` has `fit` and `transform` methods (as well as a special all-in-one, `fit_transform` method) that can be used for stateful transformation of a dataset. In the case of the `LabelEncoder`, the `fit` method discovers all unique elements in the given vector, orders them lexicographically, and assigns them an integer value. These values are actually the indices of the elements inside the `LabelEncoder.classes_` attribute, which can also be used to do a reverse lookup of the class name from the integer value. \n",
    "\n",
    "For example, if we were to encode the `gender` column of our dataset as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this is very useful for a single column, and in fact the `LabelEncoder` really was intended to encode the target variable, not necessarily categorical data expected by the classifiers.\n",
    "\n",
    "**Note:** Unfortunately, it was at this point that I realized the values all had a space in front of them. I'll address what I might have done about this in the conclusion. \n",
    "\n",
    "In order to create a multicolumn LabelEncoder, we'll have to extend the `TransformerMixin` in Scikit-Learn to create a transformer class of our own, then provide `fit` and `transform` methods that wrap individual `LabelEncoders` for our columns. My code, inspired by the StackOverflow post &ldquo;[Label encoding across multiple columns in scikit-learn](http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn)&rdquo;, is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>property_type_name</th>\n",
       "      <th>owner_occupancy_name</th>\n",
       "      <th>...</th>\n",
       "      <th>hoepa_status_name</th>\n",
       "      <th>co_applicant_sex_name</th>\n",
       "      <th>co_applicant_race_name_1</th>\n",
       "      <th>co_applicant_ethnicity_name</th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>applicant_sex_name</th>\n",
       "      <th>applicant_race_name_1</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>locality_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.660004</td>\n",
       "      <td>13024</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>3608</td>\n",
       "      <td>4642</td>\n",
       "      <td>189</td>\n",
       "      <td>69200</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.459999</td>\n",
       "      <td>8397</td>\n",
       "      <td>44.180000</td>\n",
       "      <td>1774</td>\n",
       "      <td>2579</td>\n",
       "      <td>170</td>\n",
       "      <td>74700</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.860001</td>\n",
       "      <td>3171</td>\n",
       "      <td>27.280001</td>\n",
       "      <td>882</td>\n",
       "      <td>1381</td>\n",
       "      <td>572</td>\n",
       "      <td>79300</td>\n",
       "      <td>281.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.089996</td>\n",
       "      <td>5227</td>\n",
       "      <td>93.250000</td>\n",
       "      <td>798</td>\n",
       "      <td>1075</td>\n",
       "      <td>386</td>\n",
       "      <td>63200</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.410004</td>\n",
       "      <td>5343</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>1530</td>\n",
       "      <td>2127</td>\n",
       "      <td>136</td>\n",
       "      <td>63900</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.169998</td>\n",
       "      <td>4924</td>\n",
       "      <td>32.029999</td>\n",
       "      <td>981</td>\n",
       "      <td>1894</td>\n",
       "      <td>6700</td>\n",
       "      <td>59300</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>114.910004</td>\n",
       "      <td>5562</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>1760</td>\n",
       "      <td>2200</td>\n",
       "      <td>146</td>\n",
       "      <td>65600</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68.169998</td>\n",
       "      <td>6511</td>\n",
       "      <td>37.459999</td>\n",
       "      <td>1778</td>\n",
       "      <td>2556</td>\n",
       "      <td>178</td>\n",
       "      <td>95400</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>107.050003</td>\n",
       "      <td>3711</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>1458</td>\n",
       "      <td>4130</td>\n",
       "      <td>117</td>\n",
       "      <td>50800</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>276.100006</td>\n",
       "      <td>2753</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>859</td>\n",
       "      <td>891</td>\n",
       "      <td>420</td>\n",
       "      <td>65700</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.199997</td>\n",
       "      <td>2714</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>728</td>\n",
       "      <td>929</td>\n",
       "      <td>139</td>\n",
       "      <td>75000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>67.919998</td>\n",
       "      <td>5337</td>\n",
       "      <td>78.919998</td>\n",
       "      <td>1055</td>\n",
       "      <td>1842</td>\n",
       "      <td>181</td>\n",
       "      <td>77500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>118.860001</td>\n",
       "      <td>8719</td>\n",
       "      <td>86.900002</td>\n",
       "      <td>1229</td>\n",
       "      <td>2226</td>\n",
       "      <td>180</td>\n",
       "      <td>73700</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>142.330002</td>\n",
       "      <td>20033</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>6004</td>\n",
       "      <td>6742</td>\n",
       "      <td>57</td>\n",
       "      <td>73600</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>112.900002</td>\n",
       "      <td>4007</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>1185</td>\n",
       "      <td>1449</td>\n",
       "      <td>62</td>\n",
       "      <td>59000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>75.440002</td>\n",
       "      <td>11397</td>\n",
       "      <td>66.820000</td>\n",
       "      <td>2508</td>\n",
       "      <td>3633</td>\n",
       "      <td>208</td>\n",
       "      <td>69200</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>111.370003</td>\n",
       "      <td>6529</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>2453</td>\n",
       "      <td>3352</td>\n",
       "      <td>100</td>\n",
       "      <td>65500</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80.290001</td>\n",
       "      <td>6450</td>\n",
       "      <td>54.570000</td>\n",
       "      <td>1564</td>\n",
       "      <td>2181</td>\n",
       "      <td>108</td>\n",
       "      <td>80200</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>123.620003</td>\n",
       "      <td>4810</td>\n",
       "      <td>18.090000</td>\n",
       "      <td>1626</td>\n",
       "      <td>2282</td>\n",
       "      <td>249</td>\n",
       "      <td>64300</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>2596</td>\n",
       "      <td>63.830002</td>\n",
       "      <td>312</td>\n",
       "      <td>808</td>\n",
       "      <td>59</td>\n",
       "      <td>49700</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>131.690002</td>\n",
       "      <td>3993</td>\n",
       "      <td>29.950001</td>\n",
       "      <td>856</td>\n",
       "      <td>1108</td>\n",
       "      <td>40</td>\n",
       "      <td>73400</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.669998</td>\n",
       "      <td>3120</td>\n",
       "      <td>19.129999</td>\n",
       "      <td>905</td>\n",
       "      <td>1390</td>\n",
       "      <td>179</td>\n",
       "      <td>63100</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>112.330002</td>\n",
       "      <td>3647</td>\n",
       "      <td>44.310001</td>\n",
       "      <td>1075</td>\n",
       "      <td>1273</td>\n",
       "      <td>346</td>\n",
       "      <td>107600</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85.570000</td>\n",
       "      <td>5752</td>\n",
       "      <td>53.220001</td>\n",
       "      <td>1155</td>\n",
       "      <td>1777</td>\n",
       "      <td>130</td>\n",
       "      <td>66200</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>161.809998</td>\n",
       "      <td>7269</td>\n",
       "      <td>27.170000</td>\n",
       "      <td>2212</td>\n",
       "      <td>2601</td>\n",
       "      <td>138</td>\n",
       "      <td>60400</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>241.029999</td>\n",
       "      <td>3710</td>\n",
       "      <td>7.630000</td>\n",
       "      <td>1170</td>\n",
       "      <td>1220</td>\n",
       "      <td>799</td>\n",
       "      <td>73700</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>149.580002</td>\n",
       "      <td>4121</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>1323</td>\n",
       "      <td>1531</td>\n",
       "      <td>842</td>\n",
       "      <td>89800</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>136.830002</td>\n",
       "      <td>5207</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>807</td>\n",
       "      <td>908</td>\n",
       "      <td>320</td>\n",
       "      <td>73400</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101.699997</td>\n",
       "      <td>4828</td>\n",
       "      <td>4.270000</td>\n",
       "      <td>1590</td>\n",
       "      <td>2195</td>\n",
       "      <td>30</td>\n",
       "      <td>60400</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>149.910004</td>\n",
       "      <td>4329</td>\n",
       "      <td>64.430000</td>\n",
       "      <td>1280</td>\n",
       "      <td>1817</td>\n",
       "      <td>232</td>\n",
       "      <td>46900</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>65.930000</td>\n",
       "      <td>7821</td>\n",
       "      <td>91.019997</td>\n",
       "      <td>1175</td>\n",
       "      <td>2127</td>\n",
       "      <td>145</td>\n",
       "      <td>72500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>153.130005</td>\n",
       "      <td>2719</td>\n",
       "      <td>6.470000</td>\n",
       "      <td>862</td>\n",
       "      <td>911</td>\n",
       "      <td>196</td>\n",
       "      <td>89800</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49972</th>\n",
       "      <td>101.459999</td>\n",
       "      <td>4090</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>1203</td>\n",
       "      <td>1814</td>\n",
       "      <td>78</td>\n",
       "      <td>59000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49973</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>3227</td>\n",
       "      <td>6.910000</td>\n",
       "      <td>820</td>\n",
       "      <td>1097</td>\n",
       "      <td>194</td>\n",
       "      <td>74700</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49974</th>\n",
       "      <td>97.900002</td>\n",
       "      <td>6909</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>1966</td>\n",
       "      <td>2730</td>\n",
       "      <td>48</td>\n",
       "      <td>73600</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49975</th>\n",
       "      <td>47.610001</td>\n",
       "      <td>3259</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>507</td>\n",
       "      <td>749</td>\n",
       "      <td>99</td>\n",
       "      <td>61900</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>91.300003</td>\n",
       "      <td>5944</td>\n",
       "      <td>34.720001</td>\n",
       "      <td>1587</td>\n",
       "      <td>2326</td>\n",
       "      <td>102</td>\n",
       "      <td>61600</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49977</th>\n",
       "      <td>74.650002</td>\n",
       "      <td>2482</td>\n",
       "      <td>98.150002</td>\n",
       "      <td>490</td>\n",
       "      <td>805</td>\n",
       "      <td>75</td>\n",
       "      <td>77500</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49978</th>\n",
       "      <td>100.059998</td>\n",
       "      <td>1797</td>\n",
       "      <td>8.460000</td>\n",
       "      <td>665</td>\n",
       "      <td>796</td>\n",
       "      <td>97</td>\n",
       "      <td>52600</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49979</th>\n",
       "      <td>94.889999</td>\n",
       "      <td>4923</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>1454</td>\n",
       "      <td>1983</td>\n",
       "      <td>92</td>\n",
       "      <td>68100</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49980</th>\n",
       "      <td>100.389999</td>\n",
       "      <td>5146</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>1172</td>\n",
       "      <td>2051</td>\n",
       "      <td>75</td>\n",
       "      <td>57900</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>98.559998</td>\n",
       "      <td>35527</td>\n",
       "      <td>21.920000</td>\n",
       "      <td>9575</td>\n",
       "      <td>13108</td>\n",
       "      <td>155</td>\n",
       "      <td>65500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49982</th>\n",
       "      <td>126.449997</td>\n",
       "      <td>6969</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>1985</td>\n",
       "      <td>2075</td>\n",
       "      <td>118</td>\n",
       "      <td>104800</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>76.849998</td>\n",
       "      <td>4410</td>\n",
       "      <td>80.519997</td>\n",
       "      <td>625</td>\n",
       "      <td>1358</td>\n",
       "      <td>4</td>\n",
       "      <td>73700</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>114.389999</td>\n",
       "      <td>6808</td>\n",
       "      <td>40.290001</td>\n",
       "      <td>1282</td>\n",
       "      <td>2497</td>\n",
       "      <td>71</td>\n",
       "      <td>46500</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>108.480003</td>\n",
       "      <td>1792</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>630</td>\n",
       "      <td>775</td>\n",
       "      <td>24</td>\n",
       "      <td>69900</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>61.130001</td>\n",
       "      <td>2825</td>\n",
       "      <td>96.070000</td>\n",
       "      <td>308</td>\n",
       "      <td>785</td>\n",
       "      <td>82</td>\n",
       "      <td>50000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>126.150002</td>\n",
       "      <td>11178</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>2410</td>\n",
       "      <td>3534</td>\n",
       "      <td>55</td>\n",
       "      <td>64400</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>130.529999</td>\n",
       "      <td>6392</td>\n",
       "      <td>6.490000</td>\n",
       "      <td>2095</td>\n",
       "      <td>2553</td>\n",
       "      <td>104</td>\n",
       "      <td>68200</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>119.269997</td>\n",
       "      <td>3808</td>\n",
       "      <td>26.730000</td>\n",
       "      <td>1010</td>\n",
       "      <td>1106</td>\n",
       "      <td>221</td>\n",
       "      <td>89800</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>36.240002</td>\n",
       "      <td>3490</td>\n",
       "      <td>99.510002</td>\n",
       "      <td>637</td>\n",
       "      <td>2029</td>\n",
       "      <td>92</td>\n",
       "      <td>64300</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>124.290001</td>\n",
       "      <td>4078</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1287</td>\n",
       "      <td>1522</td>\n",
       "      <td>201</td>\n",
       "      <td>77500</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>93.889999</td>\n",
       "      <td>6516</td>\n",
       "      <td>90.290001</td>\n",
       "      <td>1139</td>\n",
       "      <td>1475</td>\n",
       "      <td>250</td>\n",
       "      <td>64300</td>\n",
       "      <td>67900.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>56.360001</td>\n",
       "      <td>3437</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>921</td>\n",
       "      <td>1441</td>\n",
       "      <td>120</td>\n",
       "      <td>98200</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>131.559998</td>\n",
       "      <td>6428</td>\n",
       "      <td>73.410004</td>\n",
       "      <td>1535</td>\n",
       "      <td>2367</td>\n",
       "      <td>1</td>\n",
       "      <td>37900</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>95.459999</td>\n",
       "      <td>4007</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>1352</td>\n",
       "      <td>1614</td>\n",
       "      <td>160</td>\n",
       "      <td>71600</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>117.570000</td>\n",
       "      <td>6398</td>\n",
       "      <td>40.840000</td>\n",
       "      <td>1659</td>\n",
       "      <td>2290</td>\n",
       "      <td>413</td>\n",
       "      <td>88000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>102.430000</td>\n",
       "      <td>1684</td>\n",
       "      <td>29.930000</td>\n",
       "      <td>500</td>\n",
       "      <td>635</td>\n",
       "      <td>73</td>\n",
       "      <td>63500</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>107.459999</td>\n",
       "      <td>2304</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>688</td>\n",
       "      <td>1023</td>\n",
       "      <td>199</td>\n",
       "      <td>66200</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>99.389999</td>\n",
       "      <td>5143</td>\n",
       "      <td>41.139999</td>\n",
       "      <td>1051</td>\n",
       "      <td>1561</td>\n",
       "      <td>105</td>\n",
       "      <td>59500</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tract_to_msamd_income  population  minority_population  \\\n",
       "0                  96.660004       13024            85.070000   \n",
       "1                  58.459999        8397            44.180000   \n",
       "2                 126.860001        3171            27.280001   \n",
       "3                  82.089996        5227            93.250000   \n",
       "4                  74.410004        5343            15.480000   \n",
       "5                  92.169998        4924            32.029999   \n",
       "6                 114.910004        5562            15.550000   \n",
       "7                  68.169998        6511            37.459999   \n",
       "8                 107.050003        3711             4.720000   \n",
       "9                 276.100006        2753             7.340000   \n",
       "10                108.199997        2714             5.340000   \n",
       "11                 67.919998        5337            78.919998   \n",
       "12                118.860001        8719            86.900002   \n",
       "13                142.330002       20033             3.550000   \n",
       "14                112.900002        4007             1.220000   \n",
       "15                 75.440002       11397            66.820000   \n",
       "16                111.370003        6529            15.520000   \n",
       "17                 80.290001        6450            54.570000   \n",
       "18                123.620003        4810            18.090000   \n",
       "19                 59.000000        2596            63.830002   \n",
       "20                131.690002        3993            29.950001   \n",
       "21                100.669998        3120            19.129999   \n",
       "22                112.330002        3647            44.310001   \n",
       "23                 85.570000        5752            53.220001   \n",
       "24                161.809998        7269            27.170000   \n",
       "25                241.029999        3710             7.630000   \n",
       "26                149.580002        4121             4.460000   \n",
       "27                136.830002        5207            36.139999   \n",
       "28                101.699997        4828             4.270000   \n",
       "29                149.910004        4329            64.430000   \n",
       "...                      ...         ...                  ...   \n",
       "49970              65.930000        7821            91.019997   \n",
       "49971             153.130005        2719             6.470000   \n",
       "49972             101.459999        4090             1.980000   \n",
       "49973              86.000000        3227             6.910000   \n",
       "49974              97.900002        6909             3.790000   \n",
       "49975              47.610001        3259            24.459999   \n",
       "49976              91.300003        5944            34.720001   \n",
       "49977              74.650002        2482            98.150002   \n",
       "49978             100.059998        1797             8.460000   \n",
       "49979              94.889999        4923            10.930000   \n",
       "49980             100.389999        5146            25.299999   \n",
       "49981              98.559998       35527            21.920000   \n",
       "49982             126.449997        6969            12.460000   \n",
       "49983              76.849998        4410            80.519997   \n",
       "49984             114.389999        6808            40.290001   \n",
       "49985             108.480003        1792             2.290000   \n",
       "49986              61.130001        2825            96.070000   \n",
       "49987             126.150002       11178            19.120001   \n",
       "49988             130.529999        6392             6.490000   \n",
       "49989             119.269997        3808            26.730000   \n",
       "49990              36.240002        3490            99.510002   \n",
       "49991             124.290001        4078            28.000000   \n",
       "49992              93.889999        6516            90.290001   \n",
       "49993              56.360001        3437            23.889999   \n",
       "49994             131.559998        6428            73.410004   \n",
       "49995              95.459999        4007             6.610000   \n",
       "49996             117.570000        6398            40.840000   \n",
       "49997             102.430000        1684            29.930000   \n",
       "49998             107.459999        2304            42.099998   \n",
       "49999              99.389999        5143            41.139999   \n",
       "\n",
       "       number_of_owner_occupied_units  number_of_1_to_4_family_units  \\\n",
       "0                                3608                           4642   \n",
       "1                                1774                           2579   \n",
       "2                                 882                           1381   \n",
       "3                                 798                           1075   \n",
       "4                                1530                           2127   \n",
       "5                                 981                           1894   \n",
       "6                                1760                           2200   \n",
       "7                                1778                           2556   \n",
       "8                                1458                           4130   \n",
       "9                                 859                            891   \n",
       "10                                728                            929   \n",
       "11                               1055                           1842   \n",
       "12                               1229                           2226   \n",
       "13                               6004                           6742   \n",
       "14                               1185                           1449   \n",
       "15                               2508                           3633   \n",
       "16                               2453                           3352   \n",
       "17                               1564                           2181   \n",
       "18                               1626                           2282   \n",
       "19                                312                            808   \n",
       "20                                856                           1108   \n",
       "21                                905                           1390   \n",
       "22                               1075                           1273   \n",
       "23                               1155                           1777   \n",
       "24                               2212                           2601   \n",
       "25                               1170                           1220   \n",
       "26                               1323                           1531   \n",
       "27                                807                            908   \n",
       "28                               1590                           2195   \n",
       "29                               1280                           1817   \n",
       "...                               ...                            ...   \n",
       "49970                            1175                           2127   \n",
       "49971                             862                            911   \n",
       "49972                            1203                           1814   \n",
       "49973                             820                           1097   \n",
       "49974                            1966                           2730   \n",
       "49975                             507                            749   \n",
       "49976                            1587                           2326   \n",
       "49977                             490                            805   \n",
       "49978                             665                            796   \n",
       "49979                            1454                           1983   \n",
       "49980                            1172                           2051   \n",
       "49981                            9575                          13108   \n",
       "49982                            1985                           2075   \n",
       "49983                             625                           1358   \n",
       "49984                            1282                           2497   \n",
       "49985                             630                            775   \n",
       "49986                             308                            785   \n",
       "49987                            2410                           3534   \n",
       "49988                            2095                           2553   \n",
       "49989                            1010                           1106   \n",
       "49990                             637                           2029   \n",
       "49991                            1287                           1522   \n",
       "49992                            1139                           1475   \n",
       "49993                             921                           1441   \n",
       "49994                            1535                           2367   \n",
       "49995                            1352                           1614   \n",
       "49996                            1659                           2290   \n",
       "49997                             500                            635   \n",
       "49998                             688                           1023   \n",
       "49999                            1051                           1561   \n",
       "\n",
       "       loan_amount_000s  hud_median_family_income  applicant_income_000s  \\\n",
       "0                   189                     69200                   58.0   \n",
       "1                   170                     74700                   83.0   \n",
       "2                   572                     79300                  281.0   \n",
       "3                   386                     63200                67900.0   \n",
       "4                   136                     63900                   84.0   \n",
       "5                  6700                     59300                67900.0   \n",
       "6                   146                     65600                  138.0   \n",
       "7                   178                     95400                   78.0   \n",
       "8                   117                     50800                   25.0   \n",
       "9                   420                     65700                  215.0   \n",
       "10                  139                     75000                   89.0   \n",
       "11                  181                     77500                   40.0   \n",
       "12                  180                     73700                   77.0   \n",
       "13                   57                     73600                   75.0   \n",
       "14                   62                     59000                   46.0   \n",
       "15                  208                     69200                  140.0   \n",
       "16                  100                     65500                   72.0   \n",
       "17                  108                     80200                   59.0   \n",
       "18                  249                     64300                   98.0   \n",
       "19                   59                     49700                   40.0   \n",
       "20                   40                     73400                  105.0   \n",
       "21                  179                     63100                   53.0   \n",
       "22                  346                    107600                  144.0   \n",
       "23                  130                     66200                   32.0   \n",
       "24                  138                     60400                   42.0   \n",
       "25                  799                     73700                  220.0   \n",
       "26                  842                     89800                 2191.0   \n",
       "27                  320                     73400                  101.0   \n",
       "28                   30                     60400                   97.0   \n",
       "29                  232                     46900                67900.0   \n",
       "...                 ...                       ...                    ...   \n",
       "49970               145                     72500                   40.0   \n",
       "49971               196                     89800                   45.0   \n",
       "49972                78                     59000                   54.0   \n",
       "49973               194                     74700                   92.0   \n",
       "49974                48                     73600                  117.0   \n",
       "49975                99                     61900                   25.0   \n",
       "49976               102                     61600                   49.0   \n",
       "49977                75                     77500                   25.0   \n",
       "49978                97                     52600                   88.0   \n",
       "49979                92                     68100                   34.0   \n",
       "49980                75                     57900                   43.0   \n",
       "49981               155                     65500                   40.0   \n",
       "49982               118                    104800                   98.0   \n",
       "49983                 4                     73700                   80.0   \n",
       "49984                71                     46500                   62.0   \n",
       "49985                24                     69900                  102.0   \n",
       "49986                82                     50000                   76.0   \n",
       "49987                55                     64400                   16.0   \n",
       "49988               104                     68200                   21.0   \n",
       "49989               221                     89800                   55.0   \n",
       "49990                92                     64300                   60.0   \n",
       "49991               201                     77500                  128.0   \n",
       "49992               250                     64300                67900.0   \n",
       "49993               120                     98200                   33.0   \n",
       "49994                 1                     37900                   79.0   \n",
       "49995               160                     71600                   40.0   \n",
       "49996               413                     88000                   99.0   \n",
       "49997                73                     63500                   33.0   \n",
       "49998               199                     66200                   85.0   \n",
       "49999               105                     59500                  125.0   \n",
       "\n",
       "       property_type_name  owner_occupancy_name  ...  hoepa_status_name  \\\n",
       "0                       2                     2  ...                  1   \n",
       "1                       2                     2  ...                  1   \n",
       "2                       2                     2  ...                  1   \n",
       "3                       2                     2  ...                  1   \n",
       "4                       2                     2  ...                  1   \n",
       "5                       1                     1  ...                  1   \n",
       "6                       2                     2  ...                  1   \n",
       "7                       2                     2  ...                  1   \n",
       "8                       2                     2  ...                  1   \n",
       "9                       2                     2  ...                  1   \n",
       "10                      2                     2  ...                  1   \n",
       "11                      2                     2  ...                  1   \n",
       "12                      2                     2  ...                  1   \n",
       "13                      2                     2  ...                  1   \n",
       "14                      0                     2  ...                  1   \n",
       "15                      2                     2  ...                  1   \n",
       "16                      2                     2  ...                  1   \n",
       "17                      2                     2  ...                  1   \n",
       "18                      2                     2  ...                  1   \n",
       "19                      2                     2  ...                  1   \n",
       "20                      2                     2  ...                  1   \n",
       "21                      2                     2  ...                  1   \n",
       "22                      2                     2  ...                  1   \n",
       "23                      2                     2  ...                  1   \n",
       "24                      2                     2  ...                  1   \n",
       "25                      2                     2  ...                  1   \n",
       "26                      2                     2  ...                  1   \n",
       "27                      2                     2  ...                  1   \n",
       "28                      2                     2  ...                  1   \n",
       "29                      2                     2  ...                  1   \n",
       "...                   ...                   ...  ...                ...   \n",
       "49970                   2                     2  ...                  1   \n",
       "49971                   2                     2  ...                  1   \n",
       "49972                   2                     2  ...                  1   \n",
       "49973                   2                     2  ...                  1   \n",
       "49974                   0                     1  ...                  1   \n",
       "49975                   2                     2  ...                  1   \n",
       "49976                   0                     2  ...                  1   \n",
       "49977                   2                     2  ...                  1   \n",
       "49978                   0                     2  ...                  1   \n",
       "49979                   0                     2  ...                  1   \n",
       "49980                   2                     1  ...                  1   \n",
       "49981                   2                     2  ...                  1   \n",
       "49982                   2                     1  ...                  1   \n",
       "49983                   2                     2  ...                  1   \n",
       "49984                   0                     2  ...                  1   \n",
       "49985                   2                     2  ...                  1   \n",
       "49986                   2                     1  ...                  1   \n",
       "49987                   2                     1  ...                  1   \n",
       "49988                   2                     2  ...                  1   \n",
       "49989                   2                     2  ...                  1   \n",
       "49990                   2                     2  ...                  1   \n",
       "49991                   2                     2  ...                  1   \n",
       "49992                   2                     2  ...                  1   \n",
       "49993                   2                     2  ...                  1   \n",
       "49994                   0                     2  ...                  1   \n",
       "49995                   2                     2  ...                  1   \n",
       "49996                   2                     2  ...                  1   \n",
       "49997                   2                     2  ...                  1   \n",
       "49998                   2                     2  ...                  1   \n",
       "49999                   2                     1  ...                  1   \n",
       "\n",
       "       co_applicant_sex_name  co_applicant_race_name_1  \\\n",
       "0                          3                         5   \n",
       "1                          0                         7   \n",
       "2                          0                         7   \n",
       "3                          4                         6   \n",
       "4                          3                         5   \n",
       "5                          3                         5   \n",
       "6                          0                         7   \n",
       "7                          0                         1   \n",
       "8                          3                         5   \n",
       "9                          3                         5   \n",
       "10                         0                         7   \n",
       "11                         3                         5   \n",
       "12                         3                         5   \n",
       "13                         0                         7   \n",
       "14                         0                         7   \n",
       "15                         1                         3   \n",
       "16                         3                         5   \n",
       "17                         2                         7   \n",
       "18                         3                         5   \n",
       "19                         3                         5   \n",
       "20                         3                         5   \n",
       "21                         0                         7   \n",
       "22                         3                         5   \n",
       "23                         3                         5   \n",
       "24                         3                         5   \n",
       "25                         3                         5   \n",
       "26                         3                         5   \n",
       "27                         3                         5   \n",
       "28                         0                         7   \n",
       "29                         4                         6   \n",
       "...                      ...                       ...   \n",
       "49970                      3                         5   \n",
       "49971                      3                         5   \n",
       "49972                      0                         7   \n",
       "49973                      2                         7   \n",
       "49974                      2                         7   \n",
       "49975                      3                         5   \n",
       "49976                      2                         2   \n",
       "49977                      3                         5   \n",
       "49978                      0                         3   \n",
       "49979                      3                         5   \n",
       "49980                      3                         5   \n",
       "49981                      1                         3   \n",
       "49982                      3                         5   \n",
       "49983                      3                         5   \n",
       "49984                      0                         2   \n",
       "49985                      0                         7   \n",
       "49986                      3                         5   \n",
       "49987                      3                         5   \n",
       "49988                      1                         3   \n",
       "49989                      2                         7   \n",
       "49990                      3                         5   \n",
       "49991                      0                         2   \n",
       "49992                      2                         2   \n",
       "49993                      3                         5   \n",
       "49994                      0                         7   \n",
       "49995                      3                         5   \n",
       "49996                      0                         7   \n",
       "49997                      3                         5   \n",
       "49998                      2                         7   \n",
       "49999                      3                         5   \n",
       "\n",
       "       co_applicant_ethnicity_name  as_of_year  applicant_sex_name  \\\n",
       "0                                2        2017                   2   \n",
       "1                                3        2017                   2   \n",
       "2                                3        2017                   2   \n",
       "3                                4        2017                   3   \n",
       "4                                2        2017                   0   \n",
       "5                                2        2017                   3   \n",
       "6                                3        2017                   2   \n",
       "7                                3        2017                   2   \n",
       "8                                2        2017                   0   \n",
       "9                                2        2017                   2   \n",
       "10                               3        2017                   2   \n",
       "11                               2        2017                   2   \n",
       "12                               2        2017                   2   \n",
       "13                               3        2017                   2   \n",
       "14                               3        2017                   2   \n",
       "15                               1        2017                   1   \n",
       "16                               2        2017                   0   \n",
       "17                               3        2017                   0   \n",
       "18                               2        2017                   0   \n",
       "19                               2        2017                   2   \n",
       "20                               2        2017                   2   \n",
       "21                               3        2017                   2   \n",
       "22                               2        2017                   2   \n",
       "23                               2        2017                   2   \n",
       "24                               2        2017                   0   \n",
       "25                               2        2017                   1   \n",
       "26                               2        2017                   2   \n",
       "27                               2        2017                   2   \n",
       "28                               3        2017                   2   \n",
       "29                               4        2017                   3   \n",
       "...                            ...         ...                 ...   \n",
       "49970                            2        2017                   0   \n",
       "49971                            2        2017                   2   \n",
       "49972                            3        2017                   2   \n",
       "49973                            3        2017                   2   \n",
       "49974                            3        2017                   0   \n",
       "49975                            2        2017                   2   \n",
       "49976                            3        2017                   0   \n",
       "49977                            2        2017                   0   \n",
       "49978                            3        2017                   2   \n",
       "49979                            2        2017                   2   \n",
       "49980                            2        2017                   2   \n",
       "49981                            1        2017                   1   \n",
       "49982                            2        2017                   2   \n",
       "49983                            2        2017                   2   \n",
       "49984                            3        2017                   2   \n",
       "49985                            3        2017                   2   \n",
       "49986                            2        2017                   0   \n",
       "49987                            2        2017                   0   \n",
       "49988                            1        2017                   1   \n",
       "49989                            3        2017                   0   \n",
       "49990                            2        2017                   0   \n",
       "49991                            3        2017                   2   \n",
       "49992                            3        2017                   2   \n",
       "49993                            2        2017                   0   \n",
       "49994                            3        2017                   2   \n",
       "49995                            2        2017                   0   \n",
       "49996                            3        2017                   2   \n",
       "49997                            2        2017                   0   \n",
       "49998                            3        2017                   0   \n",
       "49999                            2        2017                   0   \n",
       "\n",
       "       applicant_race_name_1  applicant_ethnicity_name  agency_abbr  \\\n",
       "0                          2                         2            3   \n",
       "1                          6                         2            3   \n",
       "2                          6                         2            3   \n",
       "3                          5                         3            0   \n",
       "4                          6                         2            1   \n",
       "5                          5                         3            2   \n",
       "6                          6                         2            1   \n",
       "7                          1                         2            0   \n",
       "8                          6                         2            3   \n",
       "9                          6                         2            0   \n",
       "10                         6                         2            2   \n",
       "11                         6                         0            3   \n",
       "12                         6                         2            0   \n",
       "13                         6                         2            5   \n",
       "14                         6                         2            1   \n",
       "15                         3                         1            3   \n",
       "16                         6                         2            0   \n",
       "17                         6                         2            0   \n",
       "18                         6                         2            4   \n",
       "19                         6                         2            5   \n",
       "20                         1                         2            0   \n",
       "21                         6                         2            5   \n",
       "22                         6                         2            3   \n",
       "23                         6                         0            3   \n",
       "24                         6                         2            3   \n",
       "25                         3                         1            0   \n",
       "26                         6                         2            3   \n",
       "27                         1                         2            3   \n",
       "28                         6                         2            1   \n",
       "29                         5                         3            3   \n",
       "...                      ...                       ...          ...   \n",
       "49970                      1                         2            0   \n",
       "49971                      6                         2            3   \n",
       "49972                      6                         2            3   \n",
       "49973                      6                         2            4   \n",
       "49974                      6                         2            5   \n",
       "49975                      0                         2            3   \n",
       "49976                      2                         2            3   \n",
       "49977                      2                         2            3   \n",
       "49978                      6                         2            3   \n",
       "49979                      6                         2            3   \n",
       "49980                      6                         2            0   \n",
       "49981                      3                         1            3   \n",
       "49982                      6                         2            1   \n",
       "49983                      2                         2            0   \n",
       "49984                      2                         2            3   \n",
       "49985                      6                         2            1   \n",
       "49986                      6                         2            3   \n",
       "49987                      6                         2            0   \n",
       "49988                      3                         1            3   \n",
       "49989                      6                         2            3   \n",
       "49990                      2                         2            4   \n",
       "49991                      2                         2            3   \n",
       "49992                      6                         0            3   \n",
       "49993                      6                         0            3   \n",
       "49994                      6                         2            3   \n",
       "49995                      6                         2            3   \n",
       "49996                      6                         2            0   \n",
       "49997                      6                         2            3   \n",
       "49998                      6                         2            3   \n",
       "49999                      2                         2            0   \n",
       "\n",
       "       locality_type  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  0  \n",
       "5                  1  \n",
       "6                  1  \n",
       "7                  1  \n",
       "8                  0  \n",
       "9                  1  \n",
       "10                 1  \n",
       "11                 1  \n",
       "12                 1  \n",
       "13                 1  \n",
       "14                 1  \n",
       "15                 1  \n",
       "16                 1  \n",
       "17                 1  \n",
       "18                 1  \n",
       "19                 1  \n",
       "20                 1  \n",
       "21                 1  \n",
       "22                 1  \n",
       "23                 1  \n",
       "24                 1  \n",
       "25                 1  \n",
       "26                 1  \n",
       "27                 1  \n",
       "28                 0  \n",
       "29                 1  \n",
       "...              ...  \n",
       "49970              1  \n",
       "49971              1  \n",
       "49972              1  \n",
       "49973              1  \n",
       "49974              1  \n",
       "49975              1  \n",
       "49976              1  \n",
       "49977              1  \n",
       "49978              1  \n",
       "49979              1  \n",
       "49980              1  \n",
       "49981              1  \n",
       "49982              1  \n",
       "49983              1  \n",
       "49984              0  \n",
       "49985              1  \n",
       "49986              1  \n",
       "49987              1  \n",
       "49988              1  \n",
       "49989              1  \n",
       "49990              1  \n",
       "49991              1  \n",
       "49992              1  \n",
       "49993              1  \n",
       "49994              1  \n",
       "49995              1  \n",
       "49996              1  \n",
       "49997              1  \n",
       "49998              1  \n",
       "49999              1  \n",
       "\n",
       "[50000 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = [col for col in columns] \n",
    "        self.encoders = None\n",
    "    \n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode. \n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns \n",
    "        \n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelEncoder().fit(data[column])\n",
    "            for column in self.columns \n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame. \n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        for column, encoder in self.encoders.items():\n",
    "            output[column] = encoder.transform(data[column])\n",
    "            \n",
    "        return output\n",
    "\n",
    "encoder = EncodeCategorical(dataset.categorical_features.keys())\n",
    "data = encoder.fit_transform(dataset.data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Manufactured housing' 'Multifamily dwelling'\n",
      " 'One-to-four family dwelling (other than manufactured housing)']\n",
      "['Not applicable' 'Not owner-occupied as a principal dwelling'\n",
      " 'Owner-occupied as a principal dwelling']\n",
      "['Conventional' 'FHA-insured' 'FSA/RHS-guaranteed' 'VA-guaranteed']\n",
      "['Home improvement' 'Home purchase' 'Refinancing']\n",
      "['Not applicable' 'Not secured by a lien' 'Secured by a first lien'\n",
      " 'Secured by a subordinate lien']\n",
      "['HOEPA loan' 'Not a HOEPA loan']\n",
      "['Female'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'Male' 'No co-applicant' 'Not applicable']\n",
      "['American Indian or Alaska Native' 'Asian' 'Black or African American'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'Native Hawaiian or Other Pacific Islander' 'No co-applicant'\n",
      " 'Not applicable' 'White']\n",
      "['Hispanic or Latino'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'No co-applicant' 'Not Hispanic or Latino' 'Not applicable']\n",
      "['Female'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'Male' 'Not applicable']\n",
      "['American Indian or Alaska Native' 'Asian' 'Black or African American'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'Native Hawaiian or Other Pacific Islander' 'Not applicable' 'White']\n",
      "['Hispanic or Latino'\n",
      " 'Information not provided by applicant in mail, Internet, or telephone application'\n",
      " 'Not Hispanic or Latino' 'Not applicable']\n",
      "['CFPB' 'FDIC' 'FRS' 'HUD' 'NCUA' 'OCC']\n"
     ]
    }
   ],
   "source": [
    "for col, lec in encoder.encoders.items():\n",
    "    try:\n",
    "        print(lec.classes_)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom imputer, like the `EncodeCategorical` transformer takes a set of columns to perform imputation on. In this case we only wrap a single `Imputer` as the `Imputer` is multicolumn &mdash; all that's required is to ensure that the correct columns are transformed. I inspected the encoders and found only three columns that had missing values in them, and passed them directly into the customer imputer. \n",
    "\n",
    "I had chosen to do the label encoding first, assuming that because the `Imputer` required numeric values, I'd be able to do the parsing in advance. However, after requiring a custom imputer, I'd say that it's probably best to deal with the missing values early, when they're still a specific value, rather than take a chance. \n",
    "\n",
    "## Model Build \n",
    "\n",
    "Now that we've finally acheived our feature extraction, we can continue on to the model build phase. To create our classifier, we're going to create a [`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that uses our feature transformers and ends in an estimator that can do classification. We can then write the entire pipeline object to disk with the `pickle`, allowing us to load it up and use it to make predictions in the future. \n",
    "\n",
    "A pipeline is a step-by-step set of transformers that takes input data and transforms it, until finally passing it to an estimator at the end. Pipelines can be constructed using a named declarative syntax so that they're easy to modify and develop. Our pipeline is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clf = Pipeline(steps=[('preprocessor', preprocessor),\\n                      ('classifier', LogisticRegression(solver='lbfgs'))])\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, int_float),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "'''clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 68)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(dataset.data, dataset.target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the indices of the categorical columns \n",
    "categorical_indexes = [\n",
    "    list(dataset.data.columns).index(key) for key in dataset.categorical_features.keys()\n",
    "]\n",
    "\n",
    "\n",
    "hmda = Pipeline([\n",
    "        ('encoder',  EncodeCategorical(dataset.categorical_features.keys())),\n",
    "        ('onehot', OneHotEncoder(categorical_features=categorical_indexes))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 68)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.fit_transform(dataset.data, dataset.target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(X, y, model, label, **kwargs):\n",
    "\n",
    "    start  = time.time() # Start the clock! \n",
    "    scores = {'precision':[], 'recall':[], 'accuracy':[], 'f1':[]}\n",
    "    \n",
    "    kf = KFold(n_splits = 12, shuffle=True, random_state=1)\n",
    "    \n",
    "    for train, test in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        \n",
    "        '''estimator = Pipeline([\n",
    "        ('extract', clone(extractor)),\n",
    "        ('model', model(**kwargs))\n",
    "        ])'''\n",
    "        estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model(**kwargs))])\n",
    "        \n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        expected  = y_test\n",
    "        predicted = estimator.predict(X_test)\n",
    "        \n",
    "        # Append our scores to the tracker\n",
    "        scores['precision'].append(metrics.precision_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['recall'].append(metrics.recall_score(expected, predicted, average=\"weighted\"))\n",
    "        scores['accuracy'].append(metrics.accuracy_score(expected, predicted))\n",
    "        scores['f1'].append(metrics.f1_score(expected, predicted, average=\"weighted\"))\n",
    "\n",
    "    # Report\n",
    "    print(\"Build and Validation of {} took {:0.3f} seconds\".format(label, time.time()-start))\n",
    "    print(\"Validation scores are as follows:\\n\")\n",
    "    print(pd.DataFrame(scores).mean())\n",
    "    \n",
    "    # Write official estimator to disk\n",
    "    estimator = model(**kwargs)\n",
    "    estimator.fit(X, y)\n",
    "    \n",
    "    outpath = label.lower().replace(\" \", \"-\") + \".pickle\"\n",
    "    with open(outpath, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "\n",
    "    print(\"\\nFitted model written to:\\n{}\".format(os.path.abspath(outpath)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Validation of HMDA Random Forest Classifier took 293.235 seconds\n",
      "Validation scores are as follows:\n",
      "\n",
      "precision    0.723938\n",
      "recall       0.721880\n",
      "accuracy     0.721880\n",
      "f1           0.721271\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'One-to-four family dwelling (other than manufactured housing)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-745237ebd9ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HMDA Random Forest Classifier\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-92-670856eff75d>\u001b[0m in \u001b[0;36mfit_and_evaluate\u001b[1;34m(X, y, model, label, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Write official estimator to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0moutpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".pickle\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'One-to-four family dwelling (other than manufactured housing)'"
     ]
    }
   ],
   "source": [
    "fit_and_evaluate(X, y, RandomForestClassifier, \"HMDA Random Forest Classifier\", n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "C:\\Users\\akx00\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('encoder', EncodeCategorical(columns=['property_type_name', 'owner_occupancy_name', 'loan_type_name', 'loan_purpose_name', 'lien_status_name', 'hoepa_status_name', 'co_applicant_sex_name', 'co_applicant_race_name_1', 'co_applicant_ethnicity_name', 'applicant_sex_name', 'applicant_race_name_1...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Delete this cell\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# we need to encode our target data as well. \n",
    "#yencode = LabelEncoder().fit(dataset.target)\n",
    "\n",
    "# figure out the indices of the categorical columns \n",
    "categorical_indexes = [\n",
    "    list(dataset.data.columns).index(key) for key in dataset.categorical_features.keys()\n",
    "]\n",
    "\n",
    "# construct the pipeline \n",
    "hmda = Pipeline([\n",
    "        ('encoder',  EncodeCategorical(dataset.categorical_features.keys())),\n",
    "        ('onehot', OneHotEncoder(categorical_features=categorical_indexes)),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "# fit the pipeline \n",
    "hmda.fit(dataset.data, dataset.target)\n",
    "#hmda.fit(dataset.data, yencode.transform(dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline first passes data through our encoder, then to the imputer, and finally to our classifier. In this case, I have chosen a `LogisticRegression`, a regularized linear model that is used to estimate a categorical dependent variable, much like the binary target we have in this case. We can then evaluate the model on the test data set using the same exact pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# encode test targets, and strip traililng '.' \n",
    "y_true = dataset.target_test\n",
    "\n",
    "# use the model to get the predicted value\n",
    "y_pred = hmda.predict(dataset.data_test)\n",
    "\n",
    "# execute classification report \n",
    "print(classification_report(y_true, y_pred, target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the process in encoding the target for the test data, I discovered that the classes in the test data set had a `\".\"` appended to the end of the class name, which I had to strip in order for the encoder to work! However, once done, I could predict the y values using the test dataset, passing the predicted and true values to the classifier report. \n",
    "\n",
    "The classifier I built does an ok job, with an F1 score of 0.77, nothing to sneer at. However, it is possible that an SVM, a Naive Bayes, or a k nearest neighbor model would do better. It is easy to construct new models using the pipeline approach that we prepared before, and I would encourage you to try it out! Furthermore, a grid search or feature analysis may lead to a higher scoring model than the one we quickly put together. Luckily, now that we've sorted out all the pipeline issues, we can get to work on inspecting and improving the model! \n",
    "\n",
    "The last step is to save our model to disk for reuse later, with the `pickle` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def dump_model(model, path='data', name='classifier.pickle'):\n",
    "    with open(os.path.join(path, name), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "dump_model(census)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also dump meta information about the date and time your model was built, who built the model, etc. But we'll skip that step here, since this post serves as a guide. \n",
    "\n",
    "## Model Operation \n",
    "\n",
    "Now it's time to explore how to use the model. To do this, we'll create a simple function that gathers input from the user on the command line, and returns a prediction with the classifier model. Moreover, this function will load the pickled model into memory to ensure the latest and greatest saved model is what's being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path='data/classifier.pickle'):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f) \n",
    "\n",
    "\n",
    "def predict(model, meta=dataset):\n",
    "    data = {} # Store the input from the user\n",
    "    \n",
    "    for column in meta['feature_names'][:-1]:\n",
    "        # Get the valid responses\n",
    "        valid = meta['categorical_features'].get(column)\n",
    "    \n",
    "        # Prompt the user for an answer until good \n",
    "        while True:\n",
    "            val = \" \" + input(\"enter {} >\".format(column))\n",
    "            if valid and val not in valid:\n",
    "                print(\"Not valid, choose one of {}\".format(valid))\n",
    "            else:\n",
    "                data[column] = val\n",
    "                break\n",
    "    \n",
    "    # Create prediction and label \n",
    "    yhat = model.predict(pd.DataFrame([data]))\n",
    "    return yencode.inverse_transform(yhat)\n",
    "            \n",
    "    \n",
    "# Execute the interface \n",
    "model = load_model()\n",
    "predict(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
