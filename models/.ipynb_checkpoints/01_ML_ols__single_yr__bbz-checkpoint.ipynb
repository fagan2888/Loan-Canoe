{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMDA Data -- Regression Modeling\n",
    "\n",
    "## Using ML with *scikit-learn* for modeling -- (01) Linear Regression & (02) Logistical Regression \n",
    "\n",
    "\n",
    "\n",
    "This notebook explores the Home Mortgage Disclosure Act (HMDA) data for one year -- 2017. We use concepts from as well as tools from our own research and further readings to create a machine learning logistical regression model along with Naive Bayes classifers for predictive properties of loan approval rates.\n",
    "\n",
    "*Note that as of July 12, 2019, HMDA data is publically available for 2007 - 2017.  \n",
    "https://www.consumerfinance.gov/data-research/hmda/explore\n",
    "\n",
    "Documentation:\n",
    "--> *add lins here*\n",
    "\n",
    "*There are many learning sources and prior work around similar topics: We draw inspiration from past Cohorts as well as learning materials from peer sources such as Kaggle and Towards Data Science*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import all the libraries we are going to utilize throughout this notebook. We import everything at the very top of this notebook for order and best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy import stats\n",
    "from pylab import*\n",
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----*\n",
    " \n",
    "Second, we establish the connection to the AWS PostgreSQL Relational Database System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres (username, password, and database name) -- we define variables and put it into a function to easily call using an engine.\n",
    "postgres_host = 'aws-pgsql-loan-canoe.cr3nrpkvgwaj.us-east-2.rds.amazonaws.com'  \n",
    "postgres_port = '5432' \n",
    "postgres_username = 'reporting_user' \n",
    "postgres_password = 'team_loan_canoe2019'\n",
    "postgres_dbname = \"paddle_loan_canoe\"\n",
    "postgres_str = ('postgresql://{username}:{password}@{host}:{port}/{dbname}'\n",
    "                .format(username = postgres_username,\n",
    "                        password = postgres_password,\n",
    "                        host = postgres_host,\n",
    "                        port = postgres_port,\n",
    "                        dbname = postgres_dbname)\n",
    "               )\n",
    "\n",
    "# Creating the connection.\n",
    "cnx = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----*\n",
    " \n",
    "Last, we use pandas to read the sql panda frame we saved from the wrangling script (see script: HMDA DATA Summ. Stats. for more )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>year</th>\n",
       "      <th>dn_reason1</th>\n",
       "      <th>agency</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>ln_type</th>\n",
       "      <th>ln_purp</th>\n",
       "      <th>ln_amt_000s</th>\n",
       "      <th>hud_med_fm_inc</th>\n",
       "      <th>pop</th>\n",
       "      <th>rt_spread</th>\n",
       "      <th>outcome_bucket</th>\n",
       "      <th>prc_blw_hs__2013_17_5yravg</th>\n",
       "      <th>prc_hs__2013_17_5yravg</th>\n",
       "      <th>prc_ba_plus__2013_17_5yravg</th>\n",
       "      <th>r_birth_2017</th>\n",
       "      <th>r_intl_mig_2017</th>\n",
       "      <th>r_natural_inc_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application denied by financial institution</td>\n",
       "      <td>2017</td>\n",
       "      <td>Credit application incomplete</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Genesee County</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>Refinancing</td>\n",
       "      <td>140</td>\n",
       "      <td>53700</td>\n",
       "      <td>8791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Denied, Not Accepted, or Withdrawn</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application denied by financial institution</td>\n",
       "      <td>2017</td>\n",
       "      <td>Credit application incomplete</td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Genesee County</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>Refinancing</td>\n",
       "      <td>140</td>\n",
       "      <td>53700</td>\n",
       "      <td>8791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Denied, Not Accepted, or Withdrawn</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loan purchased by the institution</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>Home purchase</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "      <td>4316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved or Loan Purchased by the Institution</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Loan purchased by the institution</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>Home purchase</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "      <td>4316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved or Loan Purchased by the Institution</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loan purchased by the institution</td>\n",
       "      <td>2017</td>\n",
       "      <td></td>\n",
       "      <td>Department of Housing and Urban Development</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>Home purchase</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "      <td>4316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Approved or Loan Purchased by the Institution</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outcome  year  \\\n",
       "0  Application denied by financial institution  2017   \n",
       "1  Application denied by financial institution  2017   \n",
       "2            Loan purchased by the institution  2017   \n",
       "3            Loan purchased by the institution  2017   \n",
       "4            Loan purchased by the institution  2017   \n",
       "\n",
       "                      dn_reason1                                       agency  \\\n",
       "0  Credit application incomplete  Department of Housing and Urban Development   \n",
       "1  Credit application incomplete  Department of Housing and Urban Development   \n",
       "2                                 Department of Housing and Urban Development   \n",
       "3                                 Department of Housing and Urban Development   \n",
       "4                                 Department of Housing and Urban Development   \n",
       "\n",
       "      state          county       ln_type        ln_purp  ln_amt_000s  \\\n",
       "0  Michigan  Genesee County  Conventional    Refinancing          140   \n",
       "1  Michigan  Genesee County  Conventional    Refinancing          140   \n",
       "2  Illinois     Cook County  Conventional  Home purchase          124   \n",
       "3  Illinois     Cook County  Conventional  Home purchase          124   \n",
       "4  Illinois     Cook County  Conventional  Home purchase          124   \n",
       "\n",
       "   hud_med_fm_inc   pop  rt_spread  \\\n",
       "0           53700  8791        0.0   \n",
       "1           53700  8791        0.0   \n",
       "2           77500  4316        0.0   \n",
       "3           77500  4316        0.0   \n",
       "4           77500  4316        0.0   \n",
       "\n",
       "                                  outcome_bucket  prc_blw_hs__2013_17_5yravg  \\\n",
       "0             Denied, Not Accepted, or Withdrawn                           9   \n",
       "1             Denied, Not Accepted, or Withdrawn                          10   \n",
       "2  Approved or Loan Purchased by the Institution                           4   \n",
       "3  Approved or Loan Purchased by the Institution                          14   \n",
       "4  Approved or Loan Purchased by the Institution                          21   \n",
       "\n",
       "   prc_hs__2013_17_5yravg  prc_ba_plus__2013_17_5yravg  r_birth_2017  \\\n",
       "0                      36                           21            10   \n",
       "1                      32                           20            10   \n",
       "2                      22                           40             9   \n",
       "3                      24                           37             9   \n",
       "4                      37                           15             9   \n",
       "\n",
       "   r_intl_mig_2017  r_natural_inc_2017  \n",
       "0                0                  -1  \n",
       "1                0                  -1  \n",
       "2                3                   1  \n",
       "3                3                   1  \n",
       "4                3                   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Reading the panda dataframe we wrote to_sql from the wrangling script -- note: the dataframe is already wrangled so simply we SELECT *.\n",
    "\n",
    "    # --> extracting everything from our training data into a new dataframe here, and using an index_col.\n",
    "train_2017 = psql.read_sql_query ('SELECT * FROM aa__testing.loans_2017__training', cnx, index_col='outcome').reset_index()\n",
    "\n",
    "    #--> # using pandas to view the first 5 rows for a quick spot-check.\n",
    "train_2017.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. A Simplistic Model Purely on One Feature *(note: not a regression)*\n",
    "\n",
    "Just to test this out, let's look at a simple linear (non-OLS) model that predicts purely on median household income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome_flg</th>\n",
       "      <th>hud_med_fm_inc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>53700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>53700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome_flg  hud_med_fm_inc\n",
       "0            0           53700\n",
       "1            0           53700\n",
       "2            1           77500\n",
       "3            1           77500\n",
       "4            1           77500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorizing predicted Y var (loan outcome)  & other integer vars (integer encoding) using postgreSQL and pandas.\n",
    "train_2017_en = psql.read_sql_query ('''SELECT CAST( CASE \n",
    "                                                         WHEN tr17.outcome_bucket = 'Denied, Not Accepted, or Withdrawn' \n",
    "                                                             THEN 0 ELSE 1 \n",
    "                                                     END As INT\n",
    "                                                  ) \n",
    "                                                As outcome_flg,\n",
    "                                                tr17.hud_med_fm_inc\n",
    "                                        FROM aa__testing.loans_2017__training tr17'''\n",
    "                                     , cnx)\n",
    "train_2017_en.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of loan applications approved is 0.5450705949563373.\n"
     ]
    }
   ],
   "source": [
    "# Setting some \"modeling\" variables.\n",
    "loans_total = train_2017_en.shape[0] \n",
    "loans_approved = len(train_2017_en[train_2017_en.outcome_flg == 1])\n",
    "\n",
    "# Generating what proportion of the loan applications were approved.\n",
    "proportion_approved = float(loans_approved) /loans_total\n",
    "print('The proportion of loan applications approved is %s.' % proportion_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of loan applications approved -- for households with median incomes > $75K -- is 0.6384521231522455.\n",
      "The proportion of loan applications approved -- for households with median incomes < $75K -- is 0.5069824086603518.\n"
     ]
    }
   ],
   "source": [
    "# Next step: What is a simple way to determine what proportion of the loans were approved at certain thresholds?\n",
    "\n",
    "    # --> starting by separating median household incomes into categories\n",
    "greater_than_75K = train_2017_en[train_2017_en.hud_med_fm_inc > 75000]\n",
    "less_than_75K = train_2017_en[train_2017_en.hud_med_fm_inc < 75000]\n",
    "\n",
    "    # --> determining what proportion of loans were approved for hud med inc > $75K\n",
    "proportion_greater_than_75K = float(len(greater_than_75K[greater_than_75K.outcome_flg == 1])) / len(greater_than_75K)\n",
    "print('The proportion of loan applications approved -- for households with median incomes > $75K -- is %s.' % proportion_greater_than_75K)\n",
    "\n",
    "    # --> determining what proportion of loans were approved for hud med inc < $75K    \n",
    "proportion_less_than_75K = float(len(less_than_75K[less_than_75K.outcome_flg == 1])) / len(less_than_75K)\n",
    "print('The proportion of loan applications approved -- for households with median incomes < $75K -- is %s.' % proportion_less_than_75K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Result*: This simplistic \"model\" let's us know that households with median incomes ```greater than $75K``` are much more likely to get their loan applications approved. We could say that our model:\n",
    "\n",
    "- if median HH income > 75K => loan approved (64.5 percent);     \n",
    "- if median HH income < 75K => loan not likely approved (50.7 percent).  \n",
    "\n",
    "But this means that our model is not really a \"model\", because it will be wrong more than 33 percent of the time. Therefore, with this preliminary result in mind, we move on to exploring machie learning models using Scikit-learn below.\n",
    "\n",
    "**Documentation:**\n",
    "\n",
    "(1) From CCPE Machine Learnng Labs: \n",
    "- Scikit-Learn is a powerful machine learning library implemented in Python with numeric and scientific computing powerhouses Numpy, Scipy, and matplotlib for extremely fast analysis of small to medium-sized data sets. It is open source, commercially usable and contains many modern machine learning algorithms for classification, regression, clustering, feature extraction, and optimization. For this reason Scikit-Learn is often the first tool in a data scientist's toolkit for machine learning of incoming data sets. \n",
    "- Scikit-learn will expect numeric values and no blanks  \n",
    "\n",
    "(2) See Further Resources & Works Cited Links at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Using scikit-learn -- *Linear Regression*\n",
    "\n",
    "**Documentation:**  \n",
    "(1) https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html  \n",
    "(2) https://statisticalhorizons.com/linear-vs-logistic  \n",
    "(3) model_selection: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First,** we need to do a bit more wrangling because Scikit-learn will expect numeric values and no blanks. For this model, I will leverage ```PostgreSQL``` to do wrangling in lieu of pure python (for demonstration and integration purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome_flg</th>\n",
       "      <th>loan_app_yr</th>\n",
       "      <th>occ_flg</th>\n",
       "      <th>fdic_flg</th>\n",
       "      <th>ncua_flg</th>\n",
       "      <th>dhud_flg</th>\n",
       "      <th>cfpb_flg</th>\n",
       "      <th>northeast_flg</th>\n",
       "      <th>west_flg</th>\n",
       "      <th>midwest_flg</th>\n",
       "      <th>...</th>\n",
       "      <th>fha_insured_flg</th>\n",
       "      <th>conventional_flg</th>\n",
       "      <th>va_guarnt_flg</th>\n",
       "      <th>home_purch_flg</th>\n",
       "      <th>home_improv_flg</th>\n",
       "      <th>refinance_flg</th>\n",
       "      <th>ln_amt_000s_cat</th>\n",
       "      <th>hud_med_fm_inc_000s_cat</th>\n",
       "      <th>ln_amt_000s</th>\n",
       "      <th>hud_med_fm_inc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>53700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>53700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>77500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome_flg  loan_app_yr  occ_flg  fdic_flg  ncua_flg  dhud_flg  cfpb_flg  \\\n",
       "0            0         2017        0         0         0         1         0   \n",
       "1            0         2017        0         0         0         1         0   \n",
       "2            1         2017        0         0         0         1         0   \n",
       "3            1         2017        0         0         0         1         0   \n",
       "4            1         2017        0         0         0         1         0   \n",
       "\n",
       "   northeast_flg  west_flg  midwest_flg  ...  fha_insured_flg  \\\n",
       "0              0         0            1  ...                0   \n",
       "1              0         0            1  ...                0   \n",
       "2              0         0            0  ...                0   \n",
       "3              0         0            0  ...                0   \n",
       "4              0         0            0  ...                0   \n",
       "\n",
       "   conventional_flg  va_guarnt_flg  home_purch_flg  home_improv_flg  \\\n",
       "0                 1              0               0                0   \n",
       "1                 1              0               0                0   \n",
       "2                 1              0               1                0   \n",
       "3                 1              0               1                0   \n",
       "4                 1              0               1                0   \n",
       "\n",
       "   refinance_flg  ln_amt_000s_cat  hud_med_fm_inc_000s_cat  ln_amt_000s  \\\n",
       "0              1                1                        2          140   \n",
       "1              1                1                        2          140   \n",
       "2              0                1                        3          124   \n",
       "3              0                1                        3          124   \n",
       "4              0                1                        3          124   \n",
       "\n",
       "   hud_med_fm_inc  \n",
       "0           53700  \n",
       "1           53700  \n",
       "2           77500  \n",
       "3           77500  \n",
       "4           77500  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorizing predicted Y var (loan outcome)  & other integer vars (integer encoding) using postgreSQL and pandas\n",
    "df_2017_en = psql.read_sql_query ('''SELECT \n",
    "                                            CAST (CASE \n",
    "                                                      WHEN tr17.outcome_bucket = 'Denied, Not Accepted, or Withdrawn' THEN 0 ELSE 1 \n",
    "                                                  END As INT\n",
    "                                                 ) \n",
    "                                            As outcome_flg,\n",
    "                                            tr17.year As loan_app_yr,\n",
    "                                            -- BELOW: indicator variables (i.e. dummies for agency)\n",
    "                                            CAST(CASE WHEN agency = 'Office of the Comptroller of the Currency'   THEN 1  ELSE 0  END AS INT) As OCC_flg,\n",
    "                                            CAST(CASE WHEN agency = 'Federal Deposit Insurance Corporation'       THEN 1  ELSE 0  END As INT) As FDIC_flg,\n",
    "                                            CAST(CASE WHEN agency = 'National Credit Union Administration'        THEN 1  ELSE 0  END AS INT) As NCUA_flg,\n",
    "                                            CAST(CASE WHEN agency = 'Department of Housing and Urban Development' THEN 1  ELSE 0  END As INT) AS DHUD_flg,\n",
    "                                            CAST(CASE WHEN agency = 'Consumer Financial Protection Bureau'        THEN 1  ELSE 0  END AS INT) AS CFPB_flg,\n",
    "                                            --*\n",
    "                                            -- BELOW: indicator variables (i.e. dummies for states) to categorize by U.S. geo region\n",
    "                                                      --* note: see Issue in Loan-Canoe repo for notes and development on transforming states/msa/counties\n",
    "                                            CAST(CASE WHEN lower(tr17.state) In ('new york', 'new jersey', 'connecticut', 'massachusetts', 'pennsylvania') \n",
    "                                                          THEN 1 ELSE 0 END AS INT) \n",
    "                                            As northeast_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.state) In ('colorado', 'new mexico', 'arizona', 'utah', 'california') \n",
    "                                                          THEN 1 ELSE 0 END AS INT) \n",
    "                                            As west_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.state) In ('iowa', 'ohio', 'michigan', 'wisconsin', 'north dakota', 'nebraska',\n",
    "                                                                                 'kansas') \n",
    "                                                          THEN 1 ELSE 0 END AS INT) \n",
    "                                            As midwest_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.state) In ('mississippi', 'west virginia', 'south carolina', 'arkansas', 'missouri',\n",
    "                                                                                 'kentucky', 'florida', 'virginia', 'georgia', 'texas') \n",
    "                                                          THEN 1 ELSE 0 END AS INT) \n",
    "                                            As south_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.state) = 'alaska'  THEN 1 ELSE 0 END AS INT) As alaska_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.state) = 'hawaii'  THEN 1 ELSE 0 END AS INT) As hawaii_flg,\n",
    "                                                      --> note: non-continental states are put as stand alone dummies, but could've put one dummy (i.e. 'other')\n",
    "                                            --*\n",
    "                                            -- BELOW: indiator variables (i.e. dummies for loan type)\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_type) = 'fsa/rhs-guaranteed' THEN 1 ELSE 0 END AS INT) As fsa_rhs_guarnt_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_type) = 'fha-insured'        THEN 1 ELSE 0 END AS INT) As fha_insured_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_type) = 'conventional'       THEN 1 ELSE 0 END AS INT) As conventional_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_type) = 'va-guaranteed'      THEN 1 ELSE 0 END AS INT) As va_guarnt_flg,\n",
    "                                            --*\n",
    "                                            -- BELOW: indicator variables (i.e dummies for loan purpose)\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_purp) = 'home purchase'    THEN 1 ELSE 0 END AS INT) As home_purch_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_purp) = 'home improvement' THEN 1 ELSE 0 END AS INT) As home_improv_flg,\n",
    "                                            CAST(CASE WHEN lower(tr17.ln_purp) = 'refinancing'      THEN 1 ELSE 0 END AS INT) AS refinance_flg,\n",
    "                                            --*\n",
    "                                            -- BELOW: categorical int assignment for continous targets\n",
    "                                            CASE \n",
    "                                                WHEN tr17.ln_amt_000s <= 200  THEN 1 --> category label: low\n",
    "                                                WHEN tr17.ln_amt_000s <= 500  THEN 2 --> category label: medium\n",
    "                                                WHEN tr17.ln_amt_000s  > 500  THEN 3 --> category label: high\n",
    "                                                    --> note: this categorical int assign. is important in OLS bc OLS can't handle mix of continuous and discrete.\n",
    "                                            END ln_amt_000s_cat,\n",
    "                                            CASE \n",
    "                                                WHEN tr17.hud_med_fm_inc/1000 <= 45   THEN 1 --> category label: low\n",
    "                                                WHEN tr17.hud_med_fm_inc/1000 <= 75   THEN 2 --> category label: medium\n",
    "                                                WHEN tr17.hud_med_fm_inc/1000 <= 100  THEN 3 --> category label: high\n",
    "                                                    --> note: this categorical int assign. is important in OLS bc OLS can't handle mix of continuous and discrete.\n",
    "                                            END hud_med_fm_inc_000s_cat,\n",
    "                                            --* \n",
    "                                            tr17.ln_amt_000s, tr17.hud_med_fm_inc\n",
    "                                            FROM aa__testing.loans_2017__training tr17'''\n",
    "                                     , cnx)\n",
    "df_2017_en.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OLS Linear Regression -- Key Points**\n",
    "```*Note:* These are in my own words, so that they may be pulled into our final report.```  \n",
    "\n",
    "**OLS Linear Regression:** An OLS (Ordinary Least Square) Regression is an statistical modeling estimation technique that performs to minimize the regressor's coefficient -- notated as β -- so to reduce the sum of the squared residuals.\n",
    "\n",
    "Put another way, we use this technique to estimate the coeffients of our regressors in our model to generate a function that allows us to determine how likely a mortage loan application is to be approved given the set of variables from our data. \n",
    "\n",
    "**OLS has 7 classical assumptions:**\n",
    "- The regression model in linear, correctly specified, and has an additive error term;\n",
    "- The error term has a zero population mean;\n",
    "- All explanatory variables are uncorrelated with the error term;\n",
    "- Observations of the error term are uncorrelated with each other;\n",
    "- The error term has a constant variance;\n",
    "- No explanatory variable is a perfect linear function of any other explanatory variable;\n",
    "- The error term is normally distributed.\n",
    "\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next,** I prepare the dataset - I will use 80% of the data to train our model and 20% of our data to evaluate our model:\n",
    "- Training dataset - used to train our model;\n",
    "- Testing dataset - used to test if our model is making accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hud_med_fm_inc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_amt_000s</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_app_yr</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occ_flg</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdic_flg</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total    %\n",
       "hud_med_fm_inc      0  0.0\n",
       "ln_amt_000s         0  0.0\n",
       "loan_app_yr         0  0.0\n",
       "occ_flg             0  0.0\n",
       "fdic_flg            0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas to generate an aggregate function that outputs a more detailed view of what data is missing.\n",
    "\n",
    "total = df_2017_en.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = df_2017_en.isnull().sum()/df_2017_en.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### Note: Only after confirming there is no missing data, can we move on to regressions (alternatively, we can use skipna or fillna first).\n",
    " --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ==> *Array Splicing to Split Data -- Training and Testing Sets:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "# Generating arrays and performing array splicing to split the data -- note: numpy column counter begins at 0, not 1:\n",
    "\n",
    "array = df_2017_en.values\n",
    "X = array[:,2:22] #--> keep all rows, but take only the second column all the way to the last column before the 22nd;\n",
    "Y = array[:,0]    #--> keep all rows, but take only first column (counter begins at 0 => which is the outcome_flg);\n",
    "\n",
    "# Splitting our data for model selection with random state generator of 20:\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "print( '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ==> *Running Linear Regressions the Sets of Data -- Results for R^2 and Accuracy Scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared score is 0.177\n",
      "\n",
      "The Beta coefficients are = [-3.40114290e-01 -2.33078045e-01 -2.57810343e-01 -2.54730842e-01\n",
      " -2.28321693e-01  4.04647145e-02  4.95488649e-01  3.39859763e-01\n",
      "  2.33051664e-01  1.56906645e+08 -5.69517582e+08  1.36412326e+11\n",
      "  1.36412326e+11  1.36412326e+11  1.36412326e+11 -9.32750612e+10\n",
      " -9.32750612e+10 -9.32750612e+10  1.65446433e-01  1.64819716e-01]\n"
     ]
    }
   ],
   "source": [
    "# Intializing our linear regression algorithm:\n",
    "\n",
    "reg_model = LinearRegression().fit(X, Y)\n",
    "\n",
    "print(f'The R-squared score is {reg_model.score(X, Y).round(3)}')\n",
    "print('')\n",
    "print(f'The Beta coefficients are = {reg_model.coef_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.26489482e-01, -2.48082053e-01, -2.59372162e-01, -2.55841991e-01,\n",
       "       -2.26344087e-01,  3.96031660e-02,  4.84900014e-01,  3.40648463e-01,\n",
       "        2.32903098e-01, -2.91312067e+09, -6.98210176e+09,  7.63277548e+11,\n",
       "        7.63277548e+11,  7.63277548e+11,  7.63277548e+11,  2.50148551e+12,\n",
       "        2.50148551e+12,  2.50148551e+12,  1.66499531e-01,  1.65527177e-01])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Linear Regression Model using out training set of the data:\n",
    "\n",
    "reg_model_train = LinearRegression().fit(x_train, y_train)\n",
    "xa=reg_model_train.coef_\n",
    "xa\n",
    "#print(f'The R-squared score for our training set of the data is {reg_model_train.score(x_train, y_train).round(3)}')\n",
    "#print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Beta coefficiet is of occ_flg is -0.32648948197896266\n",
      "The Beta coefficiet is of fdic_flg is -0.24808205335155292\n",
      "The Beta coefficiet is of ncua_flg is -0.25937216167892707\n",
      "The Beta coefficiet is of dhud_flg is -0.2558419906832628\n",
      "The Beta coefficiet is of cfpb_flg is -0.22634408744663834\n",
      "The Beta coefficiet is of northeast_flg is 0.03960316595349022\n",
      "The Beta coefficiet is of west_flg is 0.4849000140224471\n",
      "The Beta coefficiet is of midwest_flg is 0.3406484632601666\n",
      "The Beta coefficiet is of south_flg is 0.2329030976711811\n",
      "The Beta coefficiet is of alaska_flg is -2913120666.2475586\n",
      "The Beta coefficiet is of hawaii_flg is -6982101758.6814575\n",
      "The Beta coefficiet is of fsa_rhs_guarnt_flg is 763277548038.2003\n",
      "The Beta coefficiet is of fha_insured_flg is 763277548037.8229\n",
      "The Beta coefficiet is of conventional_flg is 763277548037.742\n",
      "The Beta coefficiet is of va_guarnt_flg is 763277548037.778\n",
      "The Beta coefficiet is of home_purch_flg is 2501485514286.323\n",
      "The Beta coefficiet is of home_improv_flg is 2501485514286.073\n",
      "The Beta coefficiet is of refinance_flg is 2501485514286.187\n",
      "The Beta coefficiet is of ln_amt_000s_cat is 0.16649953055676697\n",
      "The Beta coefficiet is of hud_med_fm_inc_000s_cat is 0.16552717720898955\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Now that we trained our model, we view the Beta terms using an array of tuples of the coefficients\n",
    "#x_train_df = pd.DataFrame(StandardScaler)().fit_trainsform(df_2017_en.), columns=df_2017_en.loc\n",
    "#x_train_col = df_2017_en.columns[(df_2017_en.values == np.asarray(x_train)[:,None])]\n",
    "\n",
    "df_col = (df_2017_en.iloc[0:1, 2:22])\n",
    "col_x = list(df_col.columns)\n",
    "cf_x = reg_model_train.coef_\n",
    "\n",
    "for colu, coeff in zip(col_x, cf_x):\n",
    "    print ('The Beta coefficiet is of {} is {}'.format(colu, coeff))\n",
    "    \n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* when we see it displayed like this, we immediately can tell that some of these coefficients make absolutely no sense! This suggests OLS may not be a good model (at least not for our data when set up with these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => ***Accuracy Score***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.6575538100581455\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(f'The accuracy score is {accuracy_score(y_test, predictions.round())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** So our un-adjusted R-squared scores are week, *and* we get an accuracy score of 0.66 for our test set of data preditions. Additionally, we got a classification warning before altering in the accuracy scorecode cell above, hinting that OLS is a poor classifier, and, in this case especially, will very likley not separate the classes correctly.  \n",
    "\n",
    "**Further Resources:**  \n",
    "(1) Stackoverflow - https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
